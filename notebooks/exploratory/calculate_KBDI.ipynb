{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5802b2-fb91-488c-bf8f-d944c37f7853",
   "metadata": {},
   "source": [
    "# Developing functions for computing the FFDI drought factor via the KBDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40477f10-6720-4fe4-b78a-5bcd10a6ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.prepare_data import _open\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78152f50-f6eb-486d-a8e5-2a9f20075914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf371490-ef9e-4e8b-a6f3-c3adeb75e71c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee6002d-52ff-4eea-bea6-235ceed57fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/forecast_analysis/lib/python3.9/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask daskboard link: http://10.6.71.72:8787/status\n"
     ]
    }
   ],
   "source": [
    "from distributed import Client\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "walltime = \"02:00:00\"\n",
    "cores = 48\n",
    "memory = \"192GB\"\n",
    "cluster = PBSCluster(\n",
    "    walltime=str(walltime),\n",
    "    cores=cores,\n",
    "    memory=str(memory),\n",
    "    job_extra=[\n",
    "        \"-q express\",\n",
    "        \"-l ncpus=\" + str(cores),\n",
    "        \"-l mem=\" + str(memory),\n",
    "        \"-P xv83\",\n",
    "        \"-l jobfs=100GB\",\n",
    "        \"-l storage=gdata/xv83\",\n",
    "    ],\n",
    "    local_directory=\"$PBS_JOBFS\",\n",
    "    header_skip=[\"select\"],\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=1)\n",
    "client = Client(cluster)\n",
    "print(f\"Dask daskboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77fb5337-0f9a-4d11-aa45-30c6305dd969",
   "metadata": {},
   "source": [
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "walltime = \"02:00:00\"\n",
    "cores = 64\n",
    "memory = \"512GB\"\n",
    "cluster = SLURMCluster(\n",
    "    walltime=str(walltime),\n",
    "    cores=cores,\n",
    "    memory=str(memory),\n",
    "    job_extra=['--qos=\"express\"'],\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=1)\n",
    "client = Client(cluster)\n",
    "print(f\"Dask daskboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea8d81-f3ea-4809-91f5-b8167b04a15b",
   "metadata": {},
   "source": [
    "## Develop on some AGCD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba7aa2-99b7-4c17-ae94-77a1dce80dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/forecast_analysis/lib/python3.9/site-packages/dask/array/core.py:4605: PerformanceWarning: Increasing number of chunks by factor of 23\n",
      "  result = blockwise(\n"
     ]
    }
   ],
   "source": [
    "prep_data = True\n",
    "\n",
    "if prep_data:\n",
    "    agcd = _open.AGCD([\"precip\", \"tmax\"], None, None)\n",
    "\n",
    "    precip = (\n",
    "        agcd[[\"precip\"]]\n",
    "        .sel(time=slice(\"1960\", None))\n",
    "        .chunk({\"time\": -1})\n",
    "    )\n",
    "    precip.to_zarr(\"agcd_precip.zarr\", mode=\"w\")\n",
    "\n",
    "    tmax = (\n",
    "        agcd[[\"tmax\"]]\n",
    "        .sel(time=slice(\"1960\", None))\n",
    "        .chunk({\"time\": -1})\n",
    "    )\n",
    "    tmax.to_zarr(\"agcd_tmax.zarr\", mode=\"w\")\n",
    "\n",
    "precip = xr.open_zarr(\"agcd_precip.zarr\")\n",
    "tmax = xr.open_zarr(\"agcd_tmax.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e81ae3-866c-4e63-b380-1cb16a916d50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate KBDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327c1af-1d13-44dd-8e39-6c7ac520718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import dask.array as dsa\n",
    "\n",
    "\n",
    "def calculate_KBDI(precip, tmax, precip_annual, use_precip_from_previous_day=False):\n",
    "    \"\"\"\n",
    "    Calculate the Keetch-Byram drought index, defined as:\n",
    "\n",
    "        KBDI_n = KBDI_n-1 âˆ’ Peff + ET\n",
    "\n",
    "    Peff is the previous 24-hour rainfall amount, precip_n, decreased by an amount to allow\n",
    "    for interception and/or runoff:\n",
    "\n",
    "        Peff = precip_n - (interception/runoff)\n",
    "\n",
    "    where the interception and/or runoff is approximated as the first 5 mm within consecutive\n",
    "    days with nonzero rainfall.\n",
    "\n",
    "    ET is the evapotransporation, estimated as:\n",
    "\n",
    "        ET = (203.2 - KBDI_n-1) * (0.968 * exp(0.0875 * tmax_n-1 + 1.5552) - 8.3)\n",
    "             -------------------------------------------------------------------- * 10 ** (-3)\n",
    "                          1 + 10.88 * exp(-0.00173 * precip_annual)\n",
    "\n",
    "    where tmax_n-1 is the previous day's max temperature and precip_annual is the mean annual\n",
    "    rainfall.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    precip : numpy array with shape [..., N]\n",
    "        Array of daily precipitation with the last axes corresponding to the time dimension\n",
    "    tmax : numpy array with shape [..., N]\n",
    "        Array of max daily temperature with the last axes corresponding to the time dimension\n",
    "    precip_annual : numpy array with shape [...]\n",
    "        Array containing the mean annual rainfall. Usually this is computed as the average over\n",
    "        a period of years corresponding the calculation period of the KBDI\n",
    "    use_precip_from_previous_day : boolean, optional\n",
    "        If True, use precip_n-1 to calculate KBDI_n. If False (default) use precip_n to calculate\n",
    "        KBDI_n. See Notes below.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Daily values represent different things in different datasets. For example:\n",
    "      - the daily precipitation values in AGCD represent the previous 24-hour rainfall at 9am\n",
    "        and the daily tmax/tmin values represent the max/min temperatures over the subsequent\n",
    "        24-hours from 9am. Thus it is appropriate to use precip_n and t_max_n-1 as above in\n",
    "        order to calculate KBDI_n from the previous 24-hour rainfaill and previous day's max\n",
    "        temperature.\n",
    "      - both the daily precipitation and daily max temperature values are assigned to 12pm on\n",
    "        a given day in CAFE and correspond to the 24-hour period centred on that time. Thus,\n",
    "        one could argue that it is appropriate to use precip_n-1 and t_max_n-1 (or precip_n\n",
    "        and tmax_n) to calculate KBDI_n.\n",
    "      - Daily reanalysis data (e.g. JRA55) is otfen referenced against the inital forecast\n",
    "        time and the precip and tmax values correspond to the 24-hour period subsequent to the\n",
    "        reference time. Thus, it is appropriate to use precip_n-1 and tmax_n-1 to calculate\n",
    "        KBDI_n.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Finkele et al. 2006 (on calculation):\n",
    "        https://webarchive.nla.gov.au/awa/20060903105143/http://www.bom.gov.au/bmrc/pubs/researchreports/RR119.pdf\n",
    "    Holgate et al. 2017 (on calculation):\n",
    "        https://www.publish.csiro.au/wf/WF16217\n",
    "    Dolling et al. 2005 (on initialisation):\n",
    "        https://www.sciencedirect.com/science/article/pii/S0168192305001802#bib5\n",
    "    \"\"\"\n",
    "\n",
    "    @jit(nopython=True)\n",
    "    def _calculate_KBDI(precip, tmax, precip_annual, use_precip_from_previous_day):\n",
    "        \"\"\"\n",
    "        Workhorse function to calculate the KBDI\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        precip : numpy array with shape [..., N]\n",
    "            Array of daily precipitation with the last axes corresponding to the time dimension\n",
    "        tmax : numpy array with shape [..., N]\n",
    "            Array of max daily temperature with the last axes corresponding to the time dimension\n",
    "        precip_annual : numpy array with shape [...]\n",
    "            Array containing the mean annual rainfall. Usually this is computed as the average over\n",
    "            a period of years corresponding the calculation period of the KBDI\n",
    "        use_precip_from_previous_day : boolean, optional\n",
    "            If True, use precip_n-1 to calculate KBDI_n. If False (default) use precip_n to calculate\n",
    "            KBDI_n.\n",
    "\n",
    "        Note, I tried writing a version of this function using dask='allowed', rather than\n",
    "        dask='parallelized', which is generally a better approach. However, the code relied on hacks\n",
    "        to use apply_gufunc or map_blocks, so I opted for this simpler approach instead. See\n",
    "        https://github.com/dougiesquire/Squire_2022_CAFE-f6/blob/1c3743d99d564a031710d03bfffe8995b3cde3f4/\n",
    "            notebooks/exploratory/calculate_KBDI.ipynb\n",
    "        \"\"\"\n",
    "\n",
    "        def calculate_Peff(precip, remaining_runoff):\n",
    "            \"\"\"\n",
    "            Return Peff term in the KBDI and the remaining runoff from the daily\n",
    "            rainfall\n",
    "            \"\"\"\n",
    "            remaining_runoff = np.where(precip > 0, remaining_runoff, 5.0)\n",
    "            runoff = np.where(precip < remaining_runoff, precip, remaining_runoff)\n",
    "            Peff = precip - runoff\n",
    "            return Peff, remaining_runoff - runoff\n",
    "\n",
    "        def calculate_ET(KBDI_prev, tmax_prev, precip_annual):\n",
    "            \"\"\"\n",
    "            Return evapotransporation (ET) term in the KBDI\n",
    "            \"\"\"\n",
    "            term_1 = 203.2 - KBDI_prev\n",
    "            term_2 = 0.968 * np.exp(0.0875 * tmax_prev + 1.5552) - 8.3\n",
    "            term_3 = 1 + 10.88 * np.exp(-0.00173 * precip_annual)\n",
    "            return 1e-3 * term_1 * term_2 / term_3\n",
    "\n",
    "        KBDI = np.zeros_like(precip)\n",
    "\n",
    "        remaining_runoff = 5.0 * np.ones_like(precip[..., 0])\n",
    "        if not use_precip_from_previous_day:\n",
    "            _, remaining_runoff = calculate_Peff(precip[..., 0], remaining_runoff)\n",
    "\n",
    "        for i in range(1, KBDI.shape[-1]):\n",
    "            precip_curr = (\n",
    "                precip[..., i - 1] if use_precip_from_previous_day else precip[..., i]\n",
    "            )\n",
    "            Peff, remaining_runoff = calculate_Peff(precip_curr, remaining_runoff)\n",
    "            ET = calculate_ET(KBDI[..., i - 1], tmax[..., i - 1], precip_annual)\n",
    "            KBDI_curr = KBDI[..., i - 1] - Peff + ET\n",
    "\n",
    "            # Limit to between 0 and 200 mm\n",
    "            KBDI[..., i] = np.where(KBDI_curr < 0, 0, KBDI_curr)\n",
    "            KBDI[..., i] = np.where(KBDI_curr > 200, 200, KBDI_curr)\n",
    "\n",
    "        return KBDI\n",
    "\n",
    "    KBDI = xr.apply_ufunc(\n",
    "        _calculate_KBDI,\n",
    "        precip,\n",
    "        tmax,\n",
    "        precip_annual,\n",
    "        use_precip_from_previous_day,\n",
    "        input_core_dims=[[\"time\"], [\"time\"], [], []],\n",
    "        output_core_dims=[[\"time\"]],\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[precip.dtype],\n",
    "    )\n",
    "\n",
    "    KBDI = KBDI.rename(\"KBDI\")\n",
    "    KBDI.attrs[\"long_name\"] = \"Keetch-Byram Drought Index (KBDI)\"\n",
    "    KBDI.attrs[\"standard_name\"] = \"Keetch-Byram Drought Index\"\n",
    "\n",
    "    return KBDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa0c1d-6254-4ea7-a56f-4b84528f76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prep_data = True\n",
    "\n",
    "if prep_data:\n",
    "    precip_annual = precip.resample(time=\"A\").sum().mean(\"time\")\n",
    "\n",
    "    KBDI = calculate_KBDI(\n",
    "        precip[\"precip\"],\n",
    "        tmax[\"tmax\"],\n",
    "        precip_annual[\"precip\"],\n",
    "    ).to_dataset()\n",
    "\n",
    "    KBDI.to_zarr(\"agcd_KBDI.zarr\", mode=\"w\")\n",
    "\n",
    "KBDI = xr.open_zarr(\"agcd_KBDI.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5ddfc-3ea0-44fc-835b-5a7a61cceae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\n",
    "    {\"lon\": 146.4, \"lat\": -34.6},\n",
    "    {\"lon\": 148.2, \"lat\": -32.7},\n",
    "    {\"lon\": 145.2, \"lat\": -36.9},\n",
    "    {\"lon\": 133.6, \"lat\": -22.5},\n",
    "    {\"lon\": 132.4, \"lat\": -14.5},\n",
    "    {\"lon\": 148.2, \"lat\": -23.6},\n",
    "    {\"lon\": 146.3, \"lat\": -20.0},\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(len(locations), 1, sharex=True, figsize=(10, 15))\n",
    "for ax, loc in zip(axs, locations):\n",
    "    KBDI[\"KBDI\"].sel(loc, method=\"nearest\").sel(time=slice(\"2010\", \"2014\")).plot(\n",
    "        ax=ax, color=\"k\"\n",
    "    )\n",
    "    ax.set_ylim(0, 200)\n",
    "    ax.set_title(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"KBDI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512546a-e487-49ec-839a-bb5f55654517",
   "metadata": {},
   "source": [
    "## Calculate Drought factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846e902-fddf-4114-bcdc-a096930cacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drought_factor(SMD, precip, limiting_function=None):\n",
    "    \"\"\"\n",
    "    Calculate the Griffiths (1998) drought factor based on the soil moisture deficit:\n",
    "\n",
    "        DF = 10.5 * (1 - exp(-(SMD + 30) / 40)) *  41 x**2 + x\n",
    "                                                 ---------------\n",
    "                                                 40*x**2 + x + 1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    SMD : xarray DataArray\n",
    "        Values of the daily soil moisture deficit (often KBDI)\n",
    "    precip : xarray DataArray\n",
    "        Values of daily precipitation.\n",
    "    limiting_function : str, optional\n",
    "        The approach to use to limit the values of the drought factor. Options are:\n",
    "        - None; x is estimated from the rainfall over the previous 20 days and the time\n",
    "          since it fell:\n",
    "                      N**1.3\n",
    "                  --------------    if N >= 1 & P > 2mm\n",
    "                  N**1.3 + P - 2\n",
    "              x =     0.8**1.3\n",
    "                  ----------------  if N = 0  & P > 2mm\n",
    "                  0.8**1.3 + P - 2\n",
    "                         1          if P < 2mm\n",
    "          see Finkele et al. 2006 for details on how P and N are estimated from daily rainfall\n",
    "        - 'xlim'; x is estimated as above and limited to:\n",
    "                            1\n",
    "                     ----------------       if SMD < 20\n",
    "                     1 + 0.1135 * SMD\n",
    "              xlim =        75\n",
    "                     ---------------------  if SMD >= 20\n",
    "                     270.525 - 1.267 * SMD\n",
    "        - 'discrete'; x is estimated as above but the resulting drought factor is limited to the\n",
    "          following values:\n",
    "                   6   if 0   <  SMD < 25\n",
    "                   7   if 25  <= SMD < 42\n",
    "              DF = 8   if 42  <= SMD < 65\n",
    "                   9   if 65  <= SMD < 100\n",
    "                   10  if 100 <= SMD < 200\n",
    "    \"\"\"\n",
    "\n",
    "    def _calculate_x(precip_windows):\n",
    "        \"\"\"\n",
    "        Return the minimum value of the x function for a given preciptation window\n",
    "\n",
    "        This function is vectorized and very memory hungry\n",
    "        \"\"\"\n",
    "\n",
    "        def _x_function(P, N):\n",
    "            \"\"\"\n",
    "            Calculate x from the accumulated rainfall within an event and the number\n",
    "            of days N since the large daily rainfall in that event\n",
    "            \"\"\"\n",
    "            x = (N**1.3) / (N**1.3 + P - 2.0)\n",
    "            x = np.where(N == 0.0, (0.8**1.3) / (0.8**1.3 + P - 2.0), x)\n",
    "            x = np.where(P <= 2.0, 1.0, x)\n",
    "            return x\n",
    "\n",
    "        # Label events (consecutive elements with P > 2) along the window axis\n",
    "        events = precip_windows > 2.0\n",
    "        event_cumsum = np.cumsum(events, axis=-1, dtype=np.int32)[..., 1:]\n",
    "        shifted_event_cumsum = np.cumsum(\n",
    "            np.where(events[..., :-1], events[..., 1:], False), axis=-1, dtype=np.int32\n",
    "        )\n",
    "        labelled_events = np.where(\n",
    "            events[..., 1:], event_cumsum - shifted_event_cumsum, 0\n",
    "        )\n",
    "\n",
    "        # Loop over all events and compute the minimum x\n",
    "        if isinstance(precip_windows, dsa.Array):\n",
    "            # 10 is the max number of events in a 20-day period. Calculating the actual\n",
    "            # max number of events will trigger computation\n",
    "            max_events = 10\n",
    "        else:\n",
    "            max_events = np.max(labelled_events)\n",
    "        for label in range(1, max_events + 1):\n",
    "            P = np.sum(\n",
    "                np.where(labelled_events == label, precip_windows[..., 1:], 0), axis=-1\n",
    "            )\n",
    "            N = 20 - np.argmax(\n",
    "                np.where(labelled_events == label, precip_windows[..., 1:], 0), axis=-1\n",
    "            )\n",
    "            if label == 1:\n",
    "                x = _x_function(P, N)\n",
    "            else:\n",
    "                x = np.minimum(x, _x_function(P, N))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _calculate_DF(SMD, x):\n",
    "        \"\"\"Calculate the drought factor using the Griffiths formula\"\"\"\n",
    "        term_1 = 10.5 * (1 - np.exp(-(SMD + 30) / 40))\n",
    "        term_2 = 41 * x**2 + x\n",
    "        term_3 = 40 * x**2 + x + 1\n",
    "        return term_1 * term_2 / term_3\n",
    "\n",
    "    def _apply_limits(x, limits):\n",
    "        \"\"\"\n",
    "        Apply limit on x, where limits is a list of conditions and corresponding\n",
    "        limits, e.g. [(condition_1, limit_1), (condition_2, limit_2)...]\n",
    "        \"\"\"\n",
    "        for condition, limit in limits:\n",
    "            x = xr.where(condition & (x > limit), limit, x)\n",
    "        return x\n",
    "\n",
    "    def _apply_xlim(x, SMD):\n",
    "        \"\"\"Limit x using the 'xlim' function\"\"\"\n",
    "        cond_1 = (SMD < 20, 1 / (1 + 0.1135 * SMD))\n",
    "        cond_2 = (SMD >= 20, 75 / (270.525 - 1.267 * SMD))\n",
    "        return _apply_limits(x, [cond_1, cond_2])\n",
    "\n",
    "    def _apply_discrete(DF, SMD):\n",
    "        \"\"\"Limit DF using the 'discrete' function\"\"\"\n",
    "        cond_1 = ((SMD > 0) & (SMD < 25), 6)\n",
    "        cond_2 = ((SMD >= 25) & (SMD < 42), 7)\n",
    "        cond_3 = ((SMD >= 42) & (SMD < 65), 8)\n",
    "        cond_4 = ((SMD >= 65) & (SMD < 100), 9)\n",
    "        cond_5 = ((SMD >= 100) & (SMD < 200), 10)\n",
    "        return _apply_limits(DF, [cond_1, cond_2, cond_3, cond_4, cond_5])\n",
    "\n",
    "    # Use a window size of 21 as the first element is dropped in the calculation of x\n",
    "    precip_rolling = precip.rolling(time=21).construct(window_dim=\"window\")\n",
    "\n",
    "    # Adjust chunk size otherwise chunks are enormous\n",
    "    if isinstance(precip_rolling.data, dsa.Array):\n",
    "        precip_rolling = precip_rolling.chunk({\"time\": \"auto\"})\n",
    "\n",
    "    x = xr.apply_ufunc(\n",
    "        _calculate_x,\n",
    "        precip_rolling,\n",
    "        input_core_dims=[[\"window\"]],\n",
    "        dask=\"allowed\",\n",
    "    )\n",
    "\n",
    "    if limiting_function is None:\n",
    "        DF = _calculate_DF(SMD, x)\n",
    "    elif limiting_function == \"xlim\":\n",
    "        DF = _calculate_DF(SMD, _apply_xlim(x, SMD))\n",
    "    elif limiting_function == \"discrete\":\n",
    "        DF = _apply_discrete(_calculate_DF(SMD, x), SMD)\n",
    "\n",
    "    DF = DF.rename(\"DF\")\n",
    "    DF.attrs[\"long_name\"] = \"Griffiths Drought Factor (DF)\"\n",
    "    DF.attrs[\"standard_name\"] = \"drought_factor\"\n",
    "    DF.attrs[\"units\"] = \"-\"\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e5f4e-15dc-49ca-8ff0-07172c15b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "KBDI_test = KBDI[\"KBDI\"].sel(locations[0])\n",
    "precip_test = precip[\"precip\"].sel(locations[0])\n",
    "\n",
    "a = calculate_drought_factor(KBDI_test, precip=precip_test)\n",
    "b = calculate_drought_factor(KBDI_test, precip=precip_test, limiting_function=\"xlim\")\n",
    "c = calculate_drought_factor(\n",
    "    KBDI_test, precip=precip_test, limiting_function=\"discrete\"\n",
    ")\n",
    "\n",
    "plt.plot(KBDI_test, a, \"ko\")\n",
    "plt.plot(KBDI_test, b, \"bo\")\n",
    "plt.plot(KBDI_test, c, \"ro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72254a09-b86e-4949-9b88-c57cbd30df2f",
   "metadata": {},
   "source": [
    "## How does this run on the full dataset?\n",
    "\n",
    "The vectorized approach is obviously very memory hungry. I had to add in automatic chunking along the time dimension after constructing the rolling object to get it to work. I also tried:\n",
    " - using `xr.apply_ufunc(..., vectorize=True)` with a `calculate_x` function that operates on vectors - this was prohibitively slow\n",
    " - using `xr.apply_ufunc(..., dask=\"allowed\")` and wrapping the (unvectorized) `calculate_x` function with numba `guvectorize` - this failed with an uninterpretable serialization error\n",
    " - using `xr.apply_ufunc(..., dask=\"allowed\")` and mapping the (unvectorized) `calculate_x` function through `dask.gufunc.apply_gufunc` with `vectorize=True` - this was also prohibitely slow\n",
    " - using `xr.apply_ufunc(..., dask=\"allowed\")` and mapping the (unvectorized) `calculate_x` function through `apply_along_axis` - this was also prohibitively slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8c340-9eea-4a10-a59f-3cf65c785919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prep_data = True\n",
    "\n",
    "if prep_data:\n",
    "    DF = calculate_drought_factor(\n",
    "        KBDI[\"KBDI\"],\n",
    "        precip[\"precip\"],\n",
    "        limiting_function=\"discrete\",\n",
    "    ).to_dataset()\n",
    "\n",
    "    DF.to_zarr(\"agcd_DF.zarr\", mode=\"w\")\n",
    "\n",
    "DF = xr.open_zarr(\"agcd_DF.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab821265-f071-44b5-9bf0-5434c4713f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"DF\"].isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06e819-cc4e-4219-8b23-2979623ef610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (forecast_analysis)",
   "language": "python",
   "name": "forecast_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
