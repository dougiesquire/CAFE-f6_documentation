{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7945d76b-1c91-45df-aeb0-97611808e890",
   "metadata": {},
   "source": [
    "# Deep dive into SST skill\n",
    "There are a few features of the SST skill that I'd like to understand better:\n",
    "\n",
    "1) Negative 4-year correlation in the Western Tropical Pacific that substantially goes away over longer verification periods\n",
    "2) Poor MSSS in CAFE-f6 in the Southern Ocean\n",
    "3) \"Better\" initialised component of ACC for CAFE-f6 than other models, but \"worse\" MSSS_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c887932-036d-4956-8264-76a29ab04c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cftime\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import dask\n",
    "\n",
    "dask.config.set(**{\"array.slicing.split_large_chunks\": False})\n",
    "\n",
    "from src import plot, utils, verify\n",
    "\n",
    "DATA_DIR = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15967517-e1b6-4d28-b19a-9874f8d18b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197e43c-5863-4f92-8dbe-a406f108167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3949312-cce6-436c-a18f-ad6653af9647",
   "metadata": {},
   "source": [
    "## 1) Negative 4-year correlation in Western Tropical Pacific that substantially goes away over longer verification periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221be63-febf-4404-ab38-d035c8e6f6d3",
   "metadata": {},
   "source": [
    "An example (similar behaviour is observed for all models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce1360-57f2-4cb2-9bef-47298cd8fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = xr.open_zarr(\n",
    "    f\"{DATA_DIR}/skill/CanESM5.HadISST.4-year.anom_1985-2014.sst_global.rXY_1985-2014.zarr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a52caa-ddf7-4833-9635-2166e067b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot.metric_maps(\n",
    "    [[s.sel(lead=59).compute()]],\n",
    "    variable=\"sst\",\n",
    "    vrange=(-1, 1),\n",
    "    headings=[[\"years 1-4\"]],\n",
    "    figsize=(9, 5),\n",
    ")\n",
    "\n",
    "ETP_box = [200, 245, 0, 25]\n",
    "WTA_box = [280, 320, 10, 25]\n",
    "\n",
    "\n",
    "def plot_box(ax, box):\n",
    "    import cartopy.crs as ccrs\n",
    "\n",
    "    ax.plot(\n",
    "        [box[0], box[1], box[1], box[0], box[0]],\n",
    "        [box[2], box[2], box[3], box[3], box[2]],\n",
    "        \"k\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "\n",
    "for box in [ETP_box, WTA_box]:\n",
    "    plot_box(f.axes[0], box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389adbe-d143-45df-b325-803961b88866",
   "metadata": {},
   "source": [
    "Let's look at some timeseries in these regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6d3fa-1362-46c5-8f7f-03c3dbce083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = xr.open_zarr(f\"{DATA_DIR}/processed/CAFEf5.4-year.anom_1991-2020.sst_global.zarr\")\n",
    "\n",
    "f6 = xr.open_zarr(f\"{DATA_DIR}/processed/CAFEf6.4-year.anom_1991-2020.sst_global.zarr\")\n",
    "\n",
    "can = xr.open_zarr(\n",
    "    f\"{DATA_DIR}/processed/CanESM5.4-year.anom_1985-2014.sst_global.zarr\"\n",
    ")\n",
    "\n",
    "ec = xr.open_zarr(\n",
    "    f\"{DATA_DIR}/processed/EC_Earth3.4-year.anom_1985-2014.sst_global.zarr\"\n",
    ")\n",
    "had = xr.open_zarr(\n",
    "    f\"{DATA_DIR}/processed/HadISST.4-year.anom_1991-2020.sst_global.zarr\"\n",
    ")\n",
    "d60 = xr.open_zarr(\n",
    "    f\"{DATA_DIR}/processed/CAFE60v1.4-year.anom_1991-2020.sst_global.zarr\"\n",
    ")\n",
    "\n",
    "f5[\"ETP\"] = utils.extract_lon_lat_box(\n",
    "    f5.mean(\"member\"), ETP_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "f6[\"ETP\"] = utils.extract_lon_lat_box(\n",
    "    f6.mean(\"member\"), ETP_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "can[\"ETP\"] = utils.extract_lon_lat_box(\n",
    "    can.mean(\"member\"), ETP_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "ec[\"ETP\"] = utils.extract_lon_lat_box(\n",
    "    ec.mean(\"member\"), ETP_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "had[\"ETP\"] = utils.extract_lon_lat_box(had, ETP_box, weighted_average=True)[\n",
    "    \"sst\"\n",
    "].compute()\n",
    "d60[\"ETP\"] = utils.extract_lon_lat_box(\n",
    "    d60.mean(\"member\"), ETP_box, weighted_average=True\n",
    ")[\"sst\"].compute()\n",
    "\n",
    "f5[\"WTA\"] = utils.extract_lon_lat_box(\n",
    "    f5.mean(\"member\"), WTA_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "f6[\"WTA\"] = utils.extract_lon_lat_box(\n",
    "    f6.mean(\"member\"), WTA_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "can[\"WTA\"] = utils.extract_lon_lat_box(\n",
    "    can.mean(\"member\"), WTA_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "ec[\"WTA\"] = utils.extract_lon_lat_box(\n",
    "    ec.mean(\"member\"), WTA_box, weighted_average=True\n",
    ")[\"sst\"]\n",
    "had[\"WTA\"] = utils.extract_lon_lat_box(had, WTA_box, weighted_average=True)[\n",
    "    \"sst\"\n",
    "].compute()\n",
    "d60[\"WTA\"] = utils.extract_lon_lat_box(\n",
    "    d60.mean(\"member\"), WTA_box, weighted_average=True\n",
    ")[\"sst\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542f7a9-3f9d-4bc7-9594-1744667a1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_period = [\"1991-01-01\", \"2020-12-31\"]\n",
    "\n",
    "f5_norm = f5 / utils.keep_period(f5, norm_period).std(\"init\")\n",
    "f6_norm = f6 / utils.keep_period(f6, norm_period).std(\"init\")\n",
    "can_norm = can / utils.keep_period(can, norm_period).std(\"init\")\n",
    "ec_norm = ec / utils.keep_period(ec, norm_period).std(\"init\")\n",
    "had_norm = had / utils.keep_period(had, norm_period).std(\"time\")\n",
    "d60_norm = d60 / utils.keep_period(d60, norm_period).std(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196bc49-2857-4881-969d-f0590900ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(hindcasts, observations, ax):\n",
    "    from itertools import cycle\n",
    "\n",
    "    for name, hindcast in hindcasts.items():\n",
    "        hindcast.plot(ax=ax, label=name)\n",
    "\n",
    "    lines = [\"-\", \"--\", \"-.\", \":\"]\n",
    "    linecycler = cycle(lines)\n",
    "    for name, observation in observations.items():\n",
    "        observation.plot(ax=ax, label=name, color=\"k\", linestyle=next(linecycler))\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645780e-2bc9-4c07-a4ea-59d6f71ecaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lead(ds, lead):\n",
    "    return ds.sel(lead=lead).swap_dims({\"init\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de86eb-f39c-431f-8e23-682fa7ebefc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 59\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "axs = fig.subplots(2, 1, sharex=True)\n",
    "\n",
    "for ax, region in zip(axs, [\"ETP\", \"WTA\"]):\n",
    "    plot_timeseries(\n",
    "        {\n",
    "            \"CAFE-f5\": get_lead(f5[region], lead),\n",
    "            \"CAFE-f6\": get_lead(f6[region], lead),\n",
    "            \"CanESM5\": get_lead(can[region], lead),\n",
    "            \"EC-Earth3\": get_lead(ec[region], lead),\n",
    "        },\n",
    "        {\"HadISST\": had[region], \"CAFE60v1\": d60[region]},\n",
    "        ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bf768-6662-41ad-b06f-a5ed75feab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_period = [\"1991-01-01\", \"2020-12-31\"]\n",
    "\n",
    "can_period = utils.keep_period(get_lead(can[[\"ETP\", \"WTA\"]], lead), verif_period)\n",
    "xs.pearson_r(\n",
    "    can_period, had[[\"ETP\", \"WTA\"]].sel(time=can_period.time), dim=\"time\"\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff963d72-0348-44ee-b4b3-7e6e7bfed8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_period = [\"1985-01-01\", \"2014-12-31\"]\n",
    "\n",
    "can_period = utils.keep_period(get_lead(can[[\"ETP\", \"WTA\"]], lead), verif_period)\n",
    "xs.pearson_r(\n",
    "    can_period, had[[\"ETP\", \"WTA\"]].sel(time=can_period.time), dim=\"time\"\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7badd9-3d73-4c64-b561-7ae88b8298a9",
   "metadata": {},
   "source": [
    "So the correlation (and other metrics) is clearly very sensitive to the verification period. Can we try to quantify this, e.g. by subsampling the CanESM5 data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bf36f-59c1-4649-ba36-3a19f86de652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_sample_length_sensitivity(*timeseries, blocksize, metric):\n",
    "    \"\"\"\n",
    "    Test the sensitivity of a metric to the sample length by calculating the metric\n",
    "    on randomly sampled blocks of specified lengths\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries: xarray Datasets\n",
    "        The timeseries required to calculate the metric, e.g. hindcasts and observations\n",
    "    blocksize: int or list of int\n",
    "        The blocksize to recalculate the metric for\n",
    "    \"\"\"\n",
    "\n",
    "    def _n_random_block_indices(size, blocksize):\n",
    "        \"\"\"\n",
    "        Returns indices to randomly resample a single block of a specified length multiple\n",
    "        times from an array.\n",
    "        \"\"\"\n",
    "        block_starts = np.arange(0, size - blocksize + 1)\n",
    "        increment = np.arange(blocksize)\n",
    "        return block_starts + np.expand_dims(increment, axis=1)\n",
    "\n",
    "    def _sample_blocks(*arrays, indices):\n",
    "        \"\"\"Bootstrap the array(s) using the provided indices\"\"\"\n",
    "        blocks = [array[indices] for array in arrays]\n",
    "        if len(blocks) == 1:\n",
    "            return blocks[0]\n",
    "        else:\n",
    "            return tuple(blocks)\n",
    "\n",
    "    timeseries = xr.align(*timeseries)\n",
    "    metric = getattr(verify, metric)\n",
    "\n",
    "    indices = _n_random_block_indices(timeseries[0].sizes[\"time\"], blocksize)\n",
    "\n",
    "    timeseries_blocks = []\n",
    "    for obj in timeseries:\n",
    "        timeseries_blocks.append(\n",
    "            xr.apply_ufunc(\n",
    "                _sample_blocks,\n",
    "                obj,\n",
    "                kwargs=dict(\n",
    "                    indices=(..., indices),\n",
    "                ),\n",
    "                input_core_dims=[[\"time\"]],\n",
    "                output_core_dims=[[\"time\", \"iteration\"]],\n",
    "                exclude_dims=set([\"time\"]),\n",
    "                dask=\"parallelized\",\n",
    "                dask_gufunc_kwargs=dict(\n",
    "                    output_sizes={\"time\": blocksize, \"iteration\": indices.shape[-1]}\n",
    "                ),\n",
    "                output_dtypes=[obj[list(obj.data_vars)[0]].dtype],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return verify._calculate_metric_from_timeseries(\n",
    "        *timeseries_blocks, metric=metric, metric_kwargs={}, significance=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03083b-9c9f-47a1-acfd-e01165b1024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"WTA\"\n",
    "\n",
    "sensitivity = {}\n",
    "blocksizes = list(range(5, 60, 5)) + [57]\n",
    "for blocksize in blocksizes:\n",
    "    sensitivity[blocksize] = metric_sample_length_sensitivity(\n",
    "        get_lead(can, lead)[[region]],\n",
    "        had[[region]],\n",
    "        blocksize=blocksize,\n",
    "        metric=\"rXY\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469d1b1-2be2-4b13-a444-f02b3e6cdfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for b, d in sensitivity.items():\n",
    "    x.extend([int(b)] * d.sizes[\"iteration\"])\n",
    "    y.extend(d[region].values)\n",
    "\n",
    "p = sns.violinplot(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    bw=0.2,\n",
    "    cut=0,\n",
    "    inner=\"stick\",\n",
    "    scale=\"width\",\n",
    ")\n",
    "\n",
    "p.set_xlabel(\"Sample size (years)\")\n",
    "p.set_ylabel(f\"ACC in {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493de5b7-146c-443a-9f35-5b7e54fb1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = xr.align(get_lead(can, lead)[\"sst\"].mean(\"member\"), had[\"sst\"])\n",
    "\n",
    "eff_sample_size = xs.effective_sample_size(a, b, dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c67a19-6307-4206-81b1-bad5e8ffab1f",
   "metadata": {},
   "source": [
    "## 2) Poor MSSS in CAFE-f6 in the Southern Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a583732-b769-4926-bee9-1c43db5efef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "258e165c-69bd-4d21-b6c2-489535d9d1c3",
   "metadata": {},
   "source": [
    "## 3) \"Better\" initialised component of ACC for CAFE-f6 than other models, but \"worse\" MSSS_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2beb1d4-a0b6-477a-b3c0-b799e24c8be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a80ddd-f477-470d-9fe6-d313e76b8ce2",
   "metadata": {},
   "source": [
    "## Something that might be revealing is to compare our forecasts to their own analysis (CAFE60v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0530c2-644c-4d72-af8e-95a1bd89e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057d875-0921-4061-a38e-c5c5e6c01a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (forecast_analysis)",
   "language": "python",
   "name": "forecast_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
