{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1ad5b-87f1-488c-ad44-417b3234d66e",
   "metadata": {},
   "source": [
    "# Developing scripts for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8bd9b7-b7e6-4c26-93a4-2c11b6f5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "007293ca-0aa0-45d8-a8a9-adcc654099f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import yaml\n",
    "import glob\n",
    "import warnings\n",
    "import xarray as xr\n",
    "from src import utils\n",
    "\n",
    "from functools import reduce, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f746def2-7bd1-429c-b1ef-5e987d0b2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_config(name):\n",
    "    \"\"\"Load a config .yaml file for a specified dataset\"\"\"\n",
    "    with open(f\"{name}.yaml\", \"r\") as reader:\n",
    "        return yaml.load(reader, Loader=yaml.BaseLoader)\n",
    "\n",
    "\n",
    "def _maybe_translate_variables(variables, translation_dict):\n",
    "    \"\"\"\n",
    "    Translate variables using provided dictionary where possible\n",
    "    \"\"\"\n",
    "    translated_variables = []\n",
    "    for v in variables:\n",
    "        try:\n",
    "            translated_variables.append(translation_dict[v])\n",
    "        except KeyError as exception:\n",
    "            translated_variables.append(v)\n",
    "    return translated_variables\n",
    "\n",
    "\n",
    "def _maybe_rename(ds, rename):\n",
    "    \"\"\"\n",
    "    Rename all variables etc that have an entry in rename\n",
    "    \"\"\"\n",
    "    for k, v in rename.items():\n",
    "        if v in ds:\n",
    "            ds = ds.rename({v: k})\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _normalise(ds, norm_dict):\n",
    "    \"\"\"\n",
    "    Rescale variables in a dataset according to provided dictionary\n",
    "    \"\"\"\n",
    "    for v in norm_dict.keys():\n",
    "        if v in ds:\n",
    "            ds[v] = ds[v] * norm_dict[v]\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _composite_function(function_dict):\n",
    "    \"\"\"\n",
    "    Return a composite function of all functions specified in a processing\n",
    "        step of a config .yaml\n",
    "    \"\"\"\n",
    "\n",
    "    def composite(*funcs):\n",
    "        def compose(f, g):\n",
    "            return lambda x: g(f(x))\n",
    "\n",
    "        return reduce(compose, funcs, lambda x: x)\n",
    "\n",
    "    funcs = []\n",
    "    for fn in function_dict.keys():\n",
    "        kws = function_dict[fn]\n",
    "        kws = {} if kws == \"\" else kws\n",
    "        funcs.append(partial(getattr(utils, fn), **kws))\n",
    "\n",
    "    return composite(*funcs)\n",
    "\n",
    "\n",
    "def JRA55(realm, variables):\n",
    "    \"\"\"Open JRA55 data following specifications in JRA55.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"JRA55\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def HadISST(variables):\n",
    "    \"\"\"Open HadISST data following specifications in HadISST.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"HadISST\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/ocean_month.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "    ds = ds.where(ds > -1000)\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def EN422(variables):\n",
    "    \"\"\"Open EN.4.2.2 data following specifications in EN422.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"EN422\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_mfdataset(\n",
    "        f\"{PATHS['EN422']}/*.nc\",\n",
    "        parallel=True,\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFEf6(realm, variables):\n",
    "    \"\"\"Open CAFEf6 forecast data following specifications in CAFEf6.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFEf6\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        preprocess = _composite_function(cfg[\"preprocess\"])\n",
    "    else:\n",
    "        preprocess = None\n",
    "\n",
    "    files = sorted(\n",
    "        glob.glob(f\"{cfg['path']}/c5-d60-pX-f6-????1101/{realm}.zarr.zip\")\n",
    "    )  # Skip May starts\n",
    "\n",
    "    ds = xr.open_mfdataset(\n",
    "        files,\n",
    "        compat=\"override\",\n",
    "        preprocess=preprocess,\n",
    "        engine=\"zarr\",\n",
    "        coords=\"minimal\",\n",
    "        parallel=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFEf5(realm, variables):\n",
    "    \"\"\"Open CAFE-f5 forecast data following specifications in CAFEf5.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFEf5\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/NOV/{realm}.zarr.zip\", engine=\"zarr\", chunks={}\n",
    "    )[variables]\n",
    "\n",
    "    # Append 2020 forecast from CAFE-f6\n",
    "    cfg_f6 = _load_config(\"CAFEf6\")\n",
    "\n",
    "    ds_2020 = xr.open_dataset(\n",
    "        f\"{cfg_f6['path']}/c5-d60-pX-f6-20201101/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables]\n",
    "    ds_2020 = ds_2020.isel(ensemble=range(10))\n",
    "    ds_2020 = utils.convert_time_to_lead(ds_2020)\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "        ds_2020 = _maybe_rename(ds_2020, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "        ds_2020 = _normalise(ds_2020, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "        ds_2020 = _composite_function(cfg[\"postprocess\"])(ds_2020)\n",
    "\n",
    "    return xr.concat([ds, ds_2020], dim=\"init\")\n",
    "\n",
    "\n",
    "def CAFE60v1(realm, variables):\n",
    "    \"\"\"Open CAFE60v1 data following specifications in CAFE60v1.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFE60v1\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(f\"{cfg['path']}/{realm}.zarr.zip\", engine=\"zarr\", chunks={})[\n",
    "        variables\n",
    "    ]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFE_hist(realm, variables):\n",
    "    \"\"\"Open CAFE historical data following specifications in CAFE_hist.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFE_hist\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    hist = xr.open_dataset(\n",
    "        f\"{cfg['path']}/c5-d60-pX-hist-19601101/ZARR/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables]\n",
    "\n",
    "    ctrl = xr.open_dataset(\n",
    "        f\"{cfg['path']}/c5-d60-pX-ctrl-19601101/ZARR/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables].mean(\"ensemble\")\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        hist = _maybe_rename(hist, cfg[\"rename\"])\n",
    "        ctrl = _maybe_rename(ctrl, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        hist = _normalise(hist, cfg[\"normalise\"])\n",
    "        ctrl = _normalise(ctrl, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        hist = _composite_function(cfg[\"postprocess\"])(hist)\n",
    "        ctrl = _composite_function(cfg[\"postprocess\"])(ctrl)\n",
    "\n",
    "    drift = ctrl.groupby(\"time.month\").map(lambda x: x - x.mean([\"time\"]))\n",
    "    return hist - drift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ca9f40e-2784-48d6-b8d2-bb5d06093a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 25 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "had = HadISST([\"sst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "62fc1808-80bc-4b9d-8317-89f7089d3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = CAFE_hist(\"atmos_isobaric_month\", [\"t_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "24f24ae8-fca5-4b8b-9d46-07b3115ffa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d60 = CAFE60v1(\"atmos_isobaric_month\", [\"t_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09e51701-becd-47cc-9ecd-40333821dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = CAFEf5(\"atmos_isobaric_month\", [\"t_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9835e6e-e267-4e03-80b5-395a589cd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6 = CAFEf6(\"atmos_isobaric_month\", [\"t_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953a0efb-bb42-439b-a251-30a46dece9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 61 times more chunks\n",
      "  return self.array[key]\n",
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 61 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "jra = JRA55(\"surface_month_cafe-grid\", [\"t_ref\", \"precip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efe2b1-60f7-4b5e-8698-e8c9341131df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61dfadd-dbf9-482b-977e-2307e53d1a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3d0b5-4443-4bba-b6ef-1ecdc83320ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67408a1f-9a27-43d8-85dc-e110754264a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45534fde-ffd1-4132-a025-b8b44b35fa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68e714c1-24d0-4757-97c1-885ae951a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _open:\n",
    "    \"\"\"\n",
    "    Class containing the dataset-specific code for opening each available dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def JRA55(path, realm, variables, _):\n",
    "        return xr.open_dataset(\n",
    "            f\"{path}/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "\n",
    "    def HadISST(path, realm, variables, _):\n",
    "        ds = xr.open_dataset(\n",
    "            f\"{path}/{realm}.zarr\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "        return ds.where(ds > -1000)\n",
    "\n",
    "    def EN422(path, _, variables, __):\n",
    "        return xr.open_mfdataset(\n",
    "            f\"{path}/*.nc\",\n",
    "            parallel=True,\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "\n",
    "    def CAFEf6(path, realm, variables, preprocess):\n",
    "        files = sorted(\n",
    "            glob.glob(f\"{path}/c5-d60-pX-f6-????1101/{realm}.zarr.zip\")\n",
    "        )  # Skip May starts\n",
    "\n",
    "        return xr.open_mfdataset(\n",
    "            files,\n",
    "            compat=\"override\",\n",
    "            preprocess=preprocess,\n",
    "            engine=\"zarr\",\n",
    "            coords=\"minimal\",\n",
    "            parallel=True,\n",
    "        )[variables]\n",
    "\n",
    "    def CAFEf5(path, realm, variables, _):\n",
    "        ds = xr.open_dataset(f\"{path}/NOV/{realm}.zarr.zip\", engine=\"zarr\", chunks={})[\n",
    "            variables\n",
    "        ]\n",
    "\n",
    "        # Append 2020 forecast from CAFE-f6\n",
    "        cfg_f6 = _load_config(\"CAFEf6\")\n",
    "        ds_2020 = xr.open_dataset(\n",
    "            f\"{cfg_f6['path']}/c5-d60-pX-f6-20201101/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "        )[variables].isel(ensemble=range(10))\n",
    "        ds_2020 = utils.convert_time_to_lead(\n",
    "            ds_2020, init_dim=\"init_date\", lead_dim=\"lead_time\"\n",
    "        )\n",
    "        ds_2020 = utils.truncate_latitudes(ds_2020)\n",
    "\n",
    "        ds = ds.assign_coords(\n",
    "            {\"time\": ds[\"time\"].compute()}\n",
    "        )  # Required for concat below\n",
    "        return xr.concat([ds, ds_2020], dim=\"init_date\")\n",
    "\n",
    "    def CAFE60v1(path, realm, variables, _):\n",
    "        return xr.open_dataset(f\"{path}/{realm}.zarr.zip\", engine=\"zarr\", chunks={})[\n",
    "            variables\n",
    "        ]\n",
    "\n",
    "    def CAFE_hist(path, realm, variables, _):\n",
    "        hist = xr.open_dataset(\n",
    "            f\"{path}/c5-d60-pX-hist-19601101/ZARR/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "        )[variables]\n",
    "\n",
    "        ctrl = xr.open_dataset(\n",
    "            f\"{path}/c5-d60-pX-ctrl-19601101/ZARR/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "        )[variables]\n",
    "\n",
    "        hist = utils.truncate_latitudes(hist)\n",
    "        ctrl = utils.truncate_latitudes(ctrl)\n",
    "\n",
    "        drift = (\n",
    "            ctrl.mean(\"ensemble\")\n",
    "            .groupby(\"time.month\")\n",
    "            .map(lambda x: x - x.mean([\"time\"]))\n",
    "        )\n",
    "        return hist - drift\n",
    "    \n",
    "    def CanESM5(path, realm, variables, _):\n",
    "        @dask.delayed\n",
    "        def _open_CanESM5_delayed(y, e, v):\n",
    "            file = f\"{path}/s{y-1}-r{e}i1p2f1/{realm}/{v}/gn/v20190429/{v}_{realm}_CanESM5_dcppA-hindcast_s{y-1}-r{e}i1p2f1_gn_{y}01-{y+9}12.nc\"\n",
    "            ds = xr.open_dataset(file, chunks={})[v]\n",
    "            return ds\n",
    "\n",
    "        def _open_CanESM5(y, e, v):\n",
    "            var_data = _open_CanESM5_delayed(y, e, v).data\n",
    "\n",
    "            # Tell Dask the delayed function returns an array, and the size and type of that array\n",
    "            return dask.array.from_delayed(var_data, d0.shape, d0.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "038aa92c-3bf2-43bf-86e5-2a30498c1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(dataset, variables, realm=None):\n",
    "    cfg = _load_config(dataset)\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        preprocess = _composite_function(cfg[\"preprocess\"])\n",
    "    else:\n",
    "        preprocess = None\n",
    "\n",
    "    ds = getattr(_open, dataset)(cfg[\"path\"], realm, variables, preprocess)\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0fd62954-4d83-42c5-b8b4-7764f2dfa782",
   "metadata": {},
   "outputs": [],
   "source": [
    "en422 = open_dataset(\"EN422\", \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e94a7884-09eb-4ad8-b62f-70d75162df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 80 times more chunks\n",
      "  return self.array[key]\n",
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 80 times more chunks\n",
      "  return self.array[key]\n",
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 80 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "h0 = open_dataset(\"CAFE_hist\", \"atmos_isobaric_month\", [\"t_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea9a9f71-e280-41b6-aaaf-ebdcd6baa796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 25 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "had = open_dataset(\"HadISST\", \"ocean_month\", [\"sst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6c8bf-341a-4c8b-8483-479cad6370ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cafe-f6 analysis)",
   "language": "python",
   "name": "cafe-f6_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
