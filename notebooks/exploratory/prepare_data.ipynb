{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1ad5b-87f1-488c-ad44-417b3234d66e",
   "metadata": {},
   "source": [
    "# Developing scripts for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8bd9b7-b7e6-4c26-93a4-2c11b6f5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e022b7-677e-4e57-b7c1-d8c60c75b948",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c69e36-74e7-4385-9717-cffa67e511fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "walltime = \"02:00:00\"\n",
    "cores = 24\n",
    "memory = \"96GB\"\n",
    "cluster = PBSCluster(\n",
    "    processes=1,\n",
    "    walltime=str(walltime),\n",
    "    cores=cores,\n",
    "    memory=str(memory),\n",
    "    job_extra=[\n",
    "        \"-l ncpus=\" + str(cores),\n",
    "        \"-l mem=\" + str(memory),\n",
    "        \"-P xv83\",\n",
    "        \"-l jobfs=100GB\",\n",
    "        \"-l storage=gdata/xv83+gdata/oi10\",\n",
    "    ],\n",
    "    local_directory=\"$PBS_JOBFS\",\n",
    "    # env_extra=['export MALLOC_TRIM_THRESHOLD_=\"0\"'],\n",
    "    header_skip=[\"select\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9aee8b2-4ed0-4224-b2c2-3934fe6539b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-b6d8ed9a-8e01-11ec-bf7c-8c0f6f611036</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://10.6.44.3:8787/status\" target=\"_blank\">http://10.6.44.3:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">6f63323a</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://10.6.44.3:8787/status\" target=\"_blank\">http://10.6.44.3:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-40b3c678-2fb9-4b7d-a27b-405565e8e36d</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.44.3:40241\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.6.44.3:8787/status\" target=\"_blank\">http://10.6.44.3:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.44.3:40241' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scale(jobs=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13832f79-6bf7-4780-aea9-eea5d8f727b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for opening data in a common format\n",
    "\n",
    "import glob\n",
    "\n",
    "import dask\n",
    "import xarray as xr\n",
    "\n",
    "import yaml\n",
    "from functools import reduce, partial\n",
    "\n",
    "from src import utils\n",
    "\n",
    "\n",
    "def _load_config(name):\n",
    "    \"\"\"Load a config .yaml file for a specified dataset\"\"\"\n",
    "    with open(name, \"r\") as reader:\n",
    "        return yaml.load(reader, Loader=yaml.SafeLoader)\n",
    "\n",
    "\n",
    "def _maybe_translate_variables(variables, translation_dict):\n",
    "    \"\"\"\n",
    "    Translate variables using provided dictionary where possible\n",
    "    \"\"\"\n",
    "    translated_variables = {}\n",
    "    for realm, var in variables.items():\n",
    "        translated_variables[realm] = []\n",
    "        for v in var:\n",
    "            try:\n",
    "                translated_variables[realm].append(translation_dict[v])\n",
    "            except KeyError as exception:\n",
    "                translated_variables[realm].append(v)\n",
    "    return translated_variables\n",
    "\n",
    "\n",
    "def _maybe_rename(ds, rename):\n",
    "    \"\"\"\n",
    "    Rename all variables etc that have an entry in rename\n",
    "    \"\"\"\n",
    "    for k, v in rename.items():\n",
    "        if v in ds:\n",
    "            ds = ds.rename({v: k})\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _scale_variables(ds, norm_dict):\n",
    "    \"\"\"\n",
    "    Rescale variables in a dataset according to provided dictionary\n",
    "    \"\"\"\n",
    "    for v in norm_dict.keys():\n",
    "        if v in ds:\n",
    "            ds[v] = float(norm_dict[v]) * ds[v]\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _composite_function(function_dict):\n",
    "    \"\"\"\n",
    "    Return a composite function of all functions specified in a processing\n",
    "        step of a config .yaml\n",
    "    \"\"\"\n",
    "\n",
    "    def composite(*funcs):\n",
    "        def compose(f, g):\n",
    "            return lambda x: g(f(x))\n",
    "\n",
    "        return reduce(compose, funcs, lambda x: x)\n",
    "\n",
    "    funcs = []\n",
    "    for fn in function_dict.keys():\n",
    "        kws = function_dict[fn]\n",
    "        kws = {} if kws is None else kws\n",
    "        funcs.append(partial(getattr(utils, fn), **kws))\n",
    "\n",
    "    return composite(*funcs)\n",
    "\n",
    "\n",
    "class _open:\n",
    "    \"\"\"\n",
    "    Class containing the dataset-specific code for opening each available dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def JRA55(variables, realm, _):\n",
    "        \"\"\"Open JRA55 variables from specified realm\"\"\"\n",
    "        path = \"/g/data/xv83/reanalyses/JRA55/\"\n",
    "        return xr.open_dataset(\n",
    "            f\"{path}/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "\n",
    "    def HadISST(variables, realm, _):\n",
    "        \"\"\"Open HadISST variables from specified realm\"\"\"\n",
    "        path = \"/g/data/xv83/reanalyses/HadISST/\"\n",
    "        ds = xr.open_dataset(\n",
    "            f\"{path}/{realm}.zarr\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "        return ds.where(ds > -1000)\n",
    "\n",
    "    def EN422(variables, _, __):\n",
    "        \"\"\"Open EN.4.2.2 variables\"\"\"\n",
    "        path = \"/g/data/xv83/reanalyses/EN.4.2.2/\"\n",
    "        return xr.open_mfdataset(\n",
    "            f\"{path}/*.nc\",\n",
    "            parallel=True,\n",
    "            use_cftime=True,\n",
    "        )[variables]\n",
    "\n",
    "    def CAFEf6(variables, realm, preprocess):\n",
    "        \"\"\"Open CAFE-f6 variables from specified realm applying preprocess prior to\n",
    "        concanenating forecasts\n",
    "        \"\"\"\n",
    "        path = \"/g/data/xv83/dcfp/CAFE-f6/\"\n",
    "        files = sorted(\n",
    "            glob.glob(f\"{path}/c5-d60-pX-f6-????1101/{realm}.zarr.zip\")\n",
    "        )  # Skip May starts\n",
    "\n",
    "        return xr.open_mfdataset(\n",
    "            files,\n",
    "            compat=\"override\",\n",
    "            preprocess=preprocess,\n",
    "            engine=\"zarr\",\n",
    "            coords=\"minimal\",\n",
    "            parallel=True,\n",
    "        )[variables]\n",
    "\n",
    "    def CAFEf5(variables, realm, _):\n",
    "        \"\"\"Open CAFE-f5 variables from specified realm, including appending first\n",
    "        10 members of CAFE-f6 for 2020 forecast\n",
    "        \"\"\"\n",
    "        path = \"/g/data/xv83/dcfp/CAFE-f5/\"\n",
    "        return xr.open_dataset(\n",
    "            f\"{path}/NOV/{realm}.zarr.zip\", engine=\"zarr\", chunks={}\n",
    "        )[variables]\n",
    "\n",
    "    def CAFE60v1(path, realm, variables, _):\n",
    "        \"\"\"Open CAFE60v1 variables from specified realm\"\"\"\n",
    "        return xr.open_dataset(f\"{path}/{realm}.zarr.zip\", engine=\"zarr\", chunks={})[\n",
    "            variables\n",
    "        ]\n",
    "\n",
    "    def CAFE_hist(variables, realm, _):\n",
    "        \"\"\"Open CAFE historical run variables from specified realm\"\"\"\n",
    "        path = \"/g/data/xv83/users/ds0092/data/CAFE/historical/WIP/\"\n",
    "        hist = xr.open_dataset(\n",
    "            f\"{path}/c5-d60-pX-hist-19601101/ZARR/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "        )[variables]\n",
    "\n",
    "        ctrl = xr.open_dataset(\n",
    "            f\"{path}/c5-d60-pX-ctrl-19601101/ZARR/{realm}.zarr.zip\",\n",
    "            engine=\"zarr\",\n",
    "            chunks={},\n",
    "        )[variables]\n",
    "\n",
    "        hist = utils.truncate_latitudes(hist)\n",
    "        ctrl = utils.truncate_latitudes(ctrl)\n",
    "\n",
    "        drift = (\n",
    "            ctrl.mean(\"ensemble\")\n",
    "            .groupby(\"time.month\")\n",
    "            .map(lambda x: x - x.mean([\"time\"]))\n",
    "        )\n",
    "        return hist - drift\n",
    "\n",
    "    def CanESM5(variables, realm, _):\n",
    "        \"\"\"Open CanESM5 dcppA-hindcast variables from specified realm\"\"\"\n",
    "\n",
    "        def _CanESM5_file(y, m, v):\n",
    "            path = \"/g/data/oi10/replicas/CMIP6/DCPP/CCCma/CanESM5/dcppA-hindcast/\"\n",
    "            version = \"v20190429\"\n",
    "            return f\"{path}/s{y-1}-r{m}i1p2f1/{realm}/{v}/gn/{version}/{v}_{realm}_CanESM5_dcppA-hindcast_s{y-1}-r{m}i1p2f1_gn_{y}01-{y+9}12.nc\"\n",
    "\n",
    "        @dask.delayed\n",
    "        def _open_CanESM5_delayed(y, m, v):\n",
    "            file = _CanESM5_file(y, m, v)\n",
    "            ds = xr.open_dataset(file, chunks={})[v]\n",
    "            return ds\n",
    "\n",
    "        def _open_CanESM5(y, m, v, d0):\n",
    "            var_data = _open_CanESM5_delayed(y, m, v).data\n",
    "            return dask.array.from_delayed(var_data, d0.shape, d0.dtype)\n",
    "\n",
    "        years = range(1981, 2018)  # CanESM5 ocean files end in 2017\n",
    "        members = range(1, 40 + 1)\n",
    "\n",
    "        ds = []\n",
    "        for v in variables:\n",
    "            f0 = _CanESM5_file(years[0], members[0], v)\n",
    "            d0 = utils.convert_time_to_lead(xr.open_dataset(f0, chunks={}))[v]\n",
    "\n",
    "            delayed = []\n",
    "            for y in years:\n",
    "                delayed.append(\n",
    "                    dask.array.stack(\n",
    "                        [_open_CanESM5(y, m, v, d0) for m in members], axis=0\n",
    "                    )\n",
    "                )\n",
    "            delayed = dask.array.stack(delayed, axis=0)\n",
    "\n",
    "            init = xr.cftime_range(\n",
    "                str(years[0]), str(years[-1]), freq=\"YS\", calendar=\"julian\"\n",
    "            )\n",
    "            time = [\n",
    "                xr.cftime_range(i, periods=120, freq=\"MS\", calendar=\"julian\")\n",
    "                for i in init\n",
    "            ]\n",
    "            ds.append(\n",
    "                xr.DataArray(\n",
    "                    delayed,\n",
    "                    dims=[\"init\", \"member\", *d0.dims],\n",
    "                    coords={\n",
    "                        \"member\": members,\n",
    "                        \"init\": init,\n",
    "                        **d0.coords,\n",
    "                        \"time\": ([\"init\", \"lead\"], time),\n",
    "                    },\n",
    "                    attrs=d0.attrs,\n",
    "                ).to_dataset(name=v)\n",
    "            )\n",
    "        return xr.merge(ds).compute()\n",
    "\n",
    "    def CanESM5_hist(variables, realm, _):\n",
    "        \"\"\"Open CanESM5 historical variables from specified realm\"\"\"\n",
    "\n",
    "        @dask.delayed\n",
    "        def _open_CanESM5_hist_delayed(f, v):\n",
    "            ds = xr.open_dataset(f, chunks={})[v]\n",
    "            return ds\n",
    "\n",
    "        def _open_CanESM5_hist(f, v):\n",
    "            var_data = _open_CanESM5_hist_delayed(f, v).data\n",
    "            return dask.array.from_delayed(var_data, d0.shape, d0.dtype)\n",
    "\n",
    "        path = \"/g/data/oi10/replicas/CMIP6/CMIP/CCCma/CanESM5/historical/\"\n",
    "        ds = []\n",
    "        members = range(1, 40 + 1)\n",
    "        for v in variables:\n",
    "            files = sorted(\n",
    "                glob.glob(\n",
    "                    f\"{path}/r*i1p2f1/{realm}/{v}/gn/v20190429/{v}_{realm}_CanESM5_historical_r*i1p2f1_gn_185001-201412.nc\"\n",
    "                )\n",
    "            )\n",
    "            d0 = xr.open_dataset(\n",
    "                files[0],\n",
    "                chunks={},\n",
    "            )[v]\n",
    "\n",
    "            delayed = dask.array.stack(\n",
    "                [_open_CanESM5_hist(f, v) for f in files], axis=0\n",
    "            )\n",
    "\n",
    "            ds.append(\n",
    "                xr.DataArray(\n",
    "                    delayed,\n",
    "                    dims=[\"member\", *d0.dims],\n",
    "                    coords={\n",
    "                        \"member\": members,\n",
    "                        **d0.coords,\n",
    "                    },\n",
    "                    attrs=d0.attrs,\n",
    "                ).to_dataset(name=v)\n",
    "            )\n",
    "\n",
    "        return xr.merge(ds).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bfe98c0c-3e8e-461e-9bed-61746cce1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(config, save_dir):\n",
    "    \"\"\"\n",
    "    Prepare a dataset according to a provided config file and save as netcdf\n",
    "    \"\"\"\n",
    "    cfg = _load_config(config)\n",
    "\n",
    "    # List of datasets that have open methods impletemented\n",
    "    methods = [\n",
    "        method_name\n",
    "        for method_name in dir(_open)\n",
    "        if callable(getattr(_open, method_name))\n",
    "    ]\n",
    "    methods = [m for m in methods if \"__\" not in m]\n",
    "\n",
    "    if \"name\" not in cfg:\n",
    "        raise ValueError(\n",
    "            f\"Please provide an entry for 'name' in the config file so that I know how to open the data. Available options are {methods}\"\n",
    "        )\n",
    "\n",
    "    if \"prepare\" in cfg:\n",
    "        # Loop over output variables\n",
    "        output_variables = cfg[\"prepare\"]\n",
    "        for variable in output_variables.keys():\n",
    "            input_variables = output_variables[variable][\"uses\"]\n",
    "\n",
    "            if \"rename\" in cfg:\n",
    "                input_variables = _maybe_translate_variables(\n",
    "                    input_variables, cfg[\"rename\"]\n",
    "                )\n",
    "\n",
    "            if \"preprocess\" in output_variables[variable]:\n",
    "                preprocess = _composite_function(\n",
    "                    output_variables[variable][\"preprocess\"]\n",
    "                )\n",
    "            else:\n",
    "                preprocess = None\n",
    "\n",
    "            if hasattr(_open, cfg[\"name\"]):\n",
    "                ds = []\n",
    "                for realm, var in input_variables.items():\n",
    "                    ds.append(getattr(_open, cfg[\"name\"])(var, realm, preprocess))\n",
    "                ds = xr.merge(ds)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"There is no method available to open '{cfg['name']}'. Please ensure that the 'name' entry in the config file matches an existing method in src.data._open, or add a new method for this data. Available methods are {methods}\"\n",
    "                )\n",
    "\n",
    "            if \"rename\" in cfg:\n",
    "                ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "            if \"scale_variables\" in cfg:\n",
    "                ds = _scale_variables(ds, cfg[\"scale_variables\"])\n",
    "\n",
    "            if \"apply\" in output_variables[variable]:\n",
    "                ds = _composite_function(output_variables[variable][\"apply\"])(ds)\n",
    "\n",
    "            ds.to_zarr(f\"{save_dir}/{cfg['name']}.{variable}.zarr\", mode=\"w\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"No variables were specified to prepare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea9a9f71-e280-41b6-aaaf-ebdcd6baa796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 25 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "config_path = \"/g/data/xv83/users/ds0092/active_projects/Squire_2022_CAFE-f6/config/\"\n",
    "save_dir = (\n",
    "    \"/g/data/xv83/users/ds0092/active_projects/Squire_2022_CAFE-f6/data/processed\"\n",
    ")\n",
    "test = prepare_dataset(f\"{config_path}/HadISST.yaml\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b41c43b-e676-4383-b3b1-6150244da04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_zarr(\n",
    "    \"/g/data/xv83/users/ds0092/active_projects/Squire_2022_CAFE-f6/data/processed/HadISST.sst.zarr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7741941-af88-4494-9f15-d97d28b0c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(datasets, yaml_suffix):\n",
    "    \"\"\" Process dataset according to specifications in a provided set of config files\n",
    "        and save output ../processed\n",
    "    \"\"\"\n",
    "    ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a154a33-54ce-4186-8467-821a855dac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802757b8-5daf-4e96-b22b-dfa8dc2a7945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c1e3a-aae2-48b0-90bc-ae4999441613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9acd6264-609c-4a88-8255-08ff789fc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JRA55(realm, variables):\n",
    "    \"\"\"Open JRA55 data following specifications in JRA55.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"JRA55\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"scale_variables\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"scale_variables\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def HadISST(variables):\n",
    "    \"\"\"Open HadISST data following specifications in HadISST.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"HadISST\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/ocean_month.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "    ds = ds.where(ds > -1000)\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def EN422(variables):\n",
    "    \"\"\"Open EN.4.2.2 data following specifications in EN422.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"EN422\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_mfdataset(\n",
    "        f\"{PATHS['EN422']}/*.nc\",\n",
    "        parallel=True,\n",
    "        use_cftime=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFEf6(realm, variables):\n",
    "    \"\"\"Open CAFEf6 forecast data following specifications in CAFEf6.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFEf6\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        preprocess = _composite_function(cfg[\"preprocess\"])\n",
    "    else:\n",
    "        preprocess = None\n",
    "\n",
    "    files = sorted(\n",
    "        glob.glob(f\"{cfg['path']}/c5-d60-pX-f6-????1101/{realm}.zarr.zip\")\n",
    "    )  # Skip May starts\n",
    "\n",
    "    ds = xr.open_mfdataset(\n",
    "        files,\n",
    "        compat=\"override\",\n",
    "        preprocess=preprocess,\n",
    "        engine=\"zarr\",\n",
    "        coords=\"minimal\",\n",
    "        parallel=True,\n",
    "    )[variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFEf5(realm, variables):\n",
    "    \"\"\"Open CAFE-f5 forecast data following specifications in CAFEf5.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFEf5\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(\n",
    "        f\"{cfg['path']}/NOV/{realm}.zarr.zip\", engine=\"zarr\", chunks={}\n",
    "    )[variables]\n",
    "\n",
    "    # Append 2020 forecast from CAFE-f6\n",
    "    cfg_f6 = _load_config(\"CAFEf6\")\n",
    "\n",
    "    ds_2020 = xr.open_dataset(\n",
    "        f\"{cfg_f6['path']}/c5-d60-pX-f6-20201101/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables]\n",
    "    ds_2020 = ds_2020.isel(ensemble=range(10))\n",
    "    ds_2020 = utils.convert_time_to_lead(ds_2020)\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "        ds_2020 = _maybe_rename(ds_2020, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "        ds_2020 = _normalise(ds_2020, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "        ds_2020 = _composite_function(cfg[\"postprocess\"])(ds_2020)\n",
    "\n",
    "    return xr.concat([ds, ds_2020], dim=\"init\")\n",
    "\n",
    "\n",
    "def CAFE60v1(realm, variables):\n",
    "    \"\"\"Open CAFE60v1 data following specifications in CAFE60v1.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFE60v1\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    ds = xr.open_dataset(f\"{cfg['path']}/{realm}.zarr.zip\", engine=\"zarr\", chunks={})[\n",
    "        variables\n",
    "    ]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        ds = _maybe_rename(ds, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        ds = _normalise(ds, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        ds = _composite_function(cfg[\"postprocess\"])(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def CAFE_hist(realm, variables):\n",
    "    \"\"\"Open CAFE historical data following specifications in CAFE_hist.yaml\"\"\"\n",
    "\n",
    "    cfg = _load_config(\"CAFE_hist\")\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        variables = _maybe_translate_variables(variables, cfg[\"rename\"])\n",
    "\n",
    "    if \"preprocess\" in cfg:\n",
    "        warnings.warn(\n",
    "            \"preprocess functions were provided but not used because the data does not require concatenation\"\n",
    "        )\n",
    "\n",
    "    hist = xr.open_dataset(\n",
    "        f\"{cfg['path']}/c5-d60-pX-hist-19601101/ZARR/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables]\n",
    "\n",
    "    ctrl = xr.open_dataset(\n",
    "        f\"{cfg['path']}/c5-d60-pX-ctrl-19601101/ZARR/{realm}.zarr.zip\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "    )[variables].mean(\"ensemble\")\n",
    "\n",
    "    if \"rename\" in cfg:\n",
    "        hist = _maybe_rename(hist, cfg[\"rename\"])\n",
    "        ctrl = _maybe_rename(ctrl, cfg[\"rename\"])\n",
    "\n",
    "    if \"normalise\" in cfg:\n",
    "        hist = _normalise(hist, cfg[\"normalise\"])\n",
    "        ctrl = _normalise(ctrl, cfg[\"normalise\"])\n",
    "\n",
    "    if \"postprocess\" in cfg:\n",
    "        hist = _composite_function(cfg[\"postprocess\"])(hist)\n",
    "        ctrl = _composite_function(cfg[\"postprocess\"])(ctrl)\n",
    "\n",
    "    drift = ctrl.groupby(\"time.month\").map(lambda x: x - x.mean([\"time\"]))\n",
    "    return hist - drift\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cafe-f6 analysis)",
   "language": "python",
   "name": "cafe-f6_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
