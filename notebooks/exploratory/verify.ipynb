{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6923c93d-af2f-469a-93a1-099059ef2994",
   "metadata": {},
   "source": [
    "# Developing scripts for skill assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66cf2e3c-4e25-452d-bd51-5773cf62d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "cartopy.config[\"pre_existing_data_dir\"] = \"../../data/cartopy-data\"\n",
    "cartopy.config[\"data_dir\"] = \"../../data/cartopy-data\"\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.verify import verify, calculate_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84448d16-79d4-42d3-a2ff-c412f9956d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0c6b9-d3d2-4cb9-8732-7e20ac4aac10",
   "metadata": {},
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83128d9a-1384-40e0-9aa8-c912bf0f3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/processed/\"\n",
    "\n",
    "hcst = xr.open_zarr(f\"{DATA_DIR}/CanESM5.annual.anom_1991-2020.sst.zarr\")\n",
    "hist = xr.open_zarr(f\"{DATA_DIR}/CanESM5_hist.annual.anom_1991-2020.sst.zarr\")\n",
    "obsv = xr.open_zarr(f\"{DATA_DIR}/HadISST.annual.anom_1991-2020.sst.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758cc0da-880e-44bc-8712-4354c6429409",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"../../config/verify/CanESM5.yml\"\n",
    "save_dir = \"../../data/skill/\"\n",
    "\n",
    "with Client(processes=False) as client:\n",
    "    verify(config, save_dir=save_dir, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b5dfe7a-ee49-4d9f-a815-9927175f054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing verification over 1970-12-01 - 2014-12-01\n",
      "CPU times: user 4.38 s, sys: 1.23 s, total: 5.61 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "a = calculate_metric(\n",
    "    hcst, \n",
    "    obsv,\n",
    "    hist,\n",
    "    metric=\"acc_initialised\", \n",
    "    transform=\"Fisher_z\",\n",
    "    significance=True\n",
    ")\n",
    "\n",
    "# with Client(processes=False) as client:\n",
    "#     a = a.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d360c-b0d1-40f3-aed6-05fc97444cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Is it faster to calculate the skill metric within `apply_ufunc`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c6732360-c8ca-4516-90ce-a80fb521532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "750425f8-c755-4ee2-ac34-e3c7af847619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 9.62 s, total: 1min 20s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def mean_error_np(a, b):\n",
    "    return np.mean(np.mean(a, axis=-1) - b, axis=-1)\n",
    "\n",
    "bootstraps = [\n",
    "    bootstrap_metric(\n",
    "        hindcast_verif_times,\n",
    "        references_verif_times,\n",
    "        dim=[\"time\", \"member\"],\n",
    "        metric=mean_error_np,\n",
    "    )\n",
    "    for _ in range(n_iterations)\n",
    "]\n",
    "a = xr.concat(\n",
    "        bootstraps, dim=\"iteration\", coords=\"minimal\", compat=\"override\"\n",
    "    )\n",
    "\n",
    "with Client() as client:\n",
    "    a = a.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f81b7398-83eb-4267-945b-55c22f534cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 10.5 s, total: 1min 31s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def mean_error(a, b):\n",
    "    return (a.mean(\"member\") - b).mean(\"time\")\n",
    "\n",
    "bootstraps = iterative_bootstrap(\n",
    "    hindcast_verif_times,\n",
    "    references_verif_times,\n",
    "    dim=[\"time\", \"member\"],\n",
    "    n_iterations=n_iterations,\n",
    ")\n",
    "\n",
    "b = mean_error(*bootstraps)\n",
    "\n",
    "with Client() as client:\n",
    "    b = b.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b46d51-bc18-48e9-8eaa-242d8d1f3f49",
   "metadata": {},
   "source": [
    "### Not by an amount that justifies the inconvenience..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6f26a-ea54-4151-ab5b-3b7f57e03ed5",
   "metadata": {},
   "source": [
    "# Old versions of bootstrapping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089188fa-3238-414b-8ec1-3456e47e5440",
   "metadata": {},
   "source": [
    "### Apply metric within ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438101d-5da7-4543-bbdb-bbf57fac7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def _nested_random_indices(sizes):\n",
    "    \"\"\"\n",
    "    Returns indices to randomly resample (with replacement) an array in a nested\n",
    "    manner. I.e. randomly resample the first dimension, then for each randomly\n",
    "    sampled element along that dimension, randomly resample the second dimension,\n",
    "    then for each randomly sampled element along that dimension, randomly resample\n",
    "    the third dimension etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sizes : OrderedDict\n",
    "        Dictionary with the names and sizes of the dimensions to resample\n",
    "    \"\"\"\n",
    "\n",
    "    shape = [s for s in sizes.values()]\n",
    "    indices = OrderedDict()\n",
    "    for ax, key in enumerate(sizes.keys()):\n",
    "        indices[key] = np.random.randint(0, shape[ax], shape[: ax + 1])\n",
    "    return indices\n",
    "\n",
    "\n",
    "def _expand_nested_random_indices(indices):\n",
    "    \"\"\"\n",
    "    Expand the dimensions of the nested input arrays so that they can be broadcast\n",
    "    and return a tuple that can be directly indexed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indices : list of numpy arrays\n",
    "        List of numpy arrays of sequentially increasing dimension as output by the\n",
    "        function `nested_random_indices`\n",
    "    \"\"\"\n",
    "    broadcast_ndim = indices[-1].ndim\n",
    "    broadcast_indices = []\n",
    "    for i, ind in enumerate(indices):\n",
    "        broadcast_indices.append(\n",
    "            np.expand_dims(ind, axis=list(range(i + 1, broadcast_ndim)))\n",
    "        )\n",
    "    return (..., *tuple(broadcast_indices))\n",
    "\n",
    "\n",
    "def bootstrap_metric(*objects, dim, metric):\n",
    "    \"\"\"\n",
    "    Bootstrap the provided array across the specified dimension(s) in a nested\n",
    "    manner. I.e. bootstrap the first provided dimension, then for each\n",
    "    bootstrapped sample along that dimenion, bootstrap the second provided\n",
    "    dimension, then for each bootstrapped sample along that dimenion...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    objects : iterable of Datasets\n",
    "        The data to bootstrap. Multiple datasets can be passes to be\n",
    "        bootstrapped in the same way. Where multiple datasets are passed,\n",
    "        all datasets need not contain all bootstrapped dimensions. However,\n",
    "        because of the bootstrapping is applied in a nested manner, the\n",
    "        dimensions in all input objects must also be nested. E.g., for\n",
    "        `dim=['d1','d2','d3']` an object with dimensions 'd1' and 'd2' is\n",
    "        valid but an object with only dimension 'd2' is not.\n",
    "    dim : str or iterable of str\n",
    "        The dimension(s) to bootstrap in a nested manner.\n",
    "    update_outer_dim_coords : boolean, optional\n",
    "        If True, the index coordinates of the outer (first) dimension in\n",
    "        dim and any non-index coordinates with this dimension are updated\n",
    "        to reflect the bootstrap shuffling along that dimension. Otherwise,\n",
    "        the data are shuffled, but the coordinates are left unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    def _bootstrap(*arrays, indices, metric):\n",
    "        \"\"\"Bootstrap the array(s) using the provided indices\"\"\"\n",
    "        bootstrapped = tuple([array[ind] for array, ind in zip(arrays, indices)])\n",
    "        metric_bootstrapped = metric(*bootstrapped)\n",
    "        return metric_bootstrapped\n",
    "\n",
    "    if isinstance(dim, str):\n",
    "        dim = [dim]\n",
    "\n",
    "    # Get the sizes of the bootstrap dimensions\n",
    "    sizes = None\n",
    "    for obj in objects:\n",
    "        try:\n",
    "            sizes = OrderedDict({d: obj.sizes[d] for d in dim})\n",
    "            break\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if sizes is None:\n",
    "        raise ValueError(\"At least one input object must contain all dimensions in dim\")\n",
    "\n",
    "    # Generate the random indices first so that we can be sure that each\n",
    "    # dask chunk uses the same indices. Note, I tried using random.seed()\n",
    "    # to achieve this but it was flaky\n",
    "    nested_indices = _nested_random_indices(sizes)  # Indices to resample all objects\n",
    "\n",
    "    # Need to expand the indices for broadcasting for each object separately\n",
    "    # as each object may have different dimensions\n",
    "    indices = []\n",
    "    input_core_dims = []\n",
    "    for obj in objects:\n",
    "        available_dims = [d for d in dim if d in obj.dims]\n",
    "        indices_to_expand = [nested_indices[key] for key in available_dims]\n",
    "\n",
    "        # Check that dimensions are nested\n",
    "        ndims = [i.ndim for i in indices_to_expand]\n",
    "        if ndims != list(range(1, len(ndims) + 1)):\n",
    "            raise ValueError(\"The dimensions of all inputs must be nested\")\n",
    "\n",
    "        indices.append(_expand_nested_random_indices(indices_to_expand))\n",
    "        input_core_dims.append(available_dims)\n",
    "\n",
    "    return xr.apply_ufunc(\n",
    "        _bootstrap,\n",
    "        *objects,\n",
    "        kwargs=dict(\n",
    "            indices=indices,\n",
    "            metric=metric,\n",
    "        ),\n",
    "        input_core_dims=input_core_dims,\n",
    "        output_core_dims=[[]],\n",
    "        keep_attrs=True,\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[float],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eb905-5420-46e0-8443-62f6b24f46ce",
   "metadata": {},
   "source": [
    "### Basic nested bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb4b52-a50f-403a-a4cc-d1b2e6a5e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def _nested_random_indices(sizes):\n",
    "    \"\"\"\n",
    "    Returns indices to randomly resample (with replacement) an array in a nested\n",
    "    manner. I.e. randomly resample the first dimension, then for each randomly\n",
    "    sampled element along that dimension, randomly resample the second dimension,\n",
    "    then for each randomly sampled element along that dimension, randomly resample\n",
    "    the third dimension etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sizes : OrderedDict\n",
    "        Dictionary with the names and sizes of the dimensions to resample\n",
    "    \"\"\"\n",
    "\n",
    "    shape = [s for s in sizes.values()]\n",
    "    indices = OrderedDict()\n",
    "    for ax, key in enumerate(sizes.keys()):\n",
    "        indices[key] = np.random.randint(0, shape[ax], shape[: ax + 1])\n",
    "    return indices\n",
    "\n",
    "\n",
    "def _expand_nested_random_indices(indices):\n",
    "    \"\"\"\n",
    "    Expand the dimensions of the nested input arrays so that they can be broadcast\n",
    "    and return a tuple that can be directly indexed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indices : list of numpy arrays\n",
    "        List of numpy arrays of sequentially increasing dimension as output by the\n",
    "        function `nested_random_indices`\n",
    "    \"\"\"\n",
    "    broadcast_ndim = indices[-1].ndim\n",
    "    broadcast_indices = []\n",
    "    for i, ind in enumerate(indices):\n",
    "        broadcast_indices.append(\n",
    "            np.expand_dims(ind, axis=list(range(i + 1, broadcast_ndim)))\n",
    "        )\n",
    "    return (..., *tuple(broadcast_indices))\n",
    "\n",
    "\n",
    "def bootstrap(*objects, dim, update_outer_dim_coords=True):\n",
    "    \"\"\"\n",
    "    Bootstrap the provided array across the specified dimension(s) in a nested\n",
    "    manner. I.e. bootstrap the first provided dimension, then for each\n",
    "    bootstrapped sample along that dimenion, bootstrap the second provided\n",
    "    dimension, then for each bootstrapped sample along that dimenion...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    objects : iterable of Datasets\n",
    "        The data to bootstrap. Multiple datasets can be passes to be\n",
    "        bootstrapped in the same way. Where multiple datasets are passed,\n",
    "        all datasets need not contain all bootstrapped dimensions. However,\n",
    "        because of the bootstrapping is applied in a nested manner, the\n",
    "        dimensions in all input objects must also be nested. E.g., for\n",
    "        `dim=['d1','d2','d3']` an object with dimensions 'd1' and 'd2' is\n",
    "        valid but an object with only dimension 'd2' is not.\n",
    "    dim : str or iterable of str\n",
    "        The dimension(s) to bootstrap in a nested manner.\n",
    "    update_outer_dim_coords : boolean, optional\n",
    "        If True, the index coordinates of the outer (first) dimension in\n",
    "        dim and any non-index coordinates with this dimension are updated\n",
    "        to reflect the bootstrap shuffling along that dimension. Otherwise,\n",
    "        the data are shuffled, but the coordinates are left unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    def _bootstrap(*arrays, indices):\n",
    "        \"\"\"Bootstrap the array(s) using the provided indices\"\"\"\n",
    "        bootstrapped = tuple([array[ind] for array, ind in zip(arrays, indices)])\n",
    "        if len(bootstrapped) == 1:\n",
    "            return bootstrapped[0]\n",
    "        else:\n",
    "            return bootstrapped\n",
    "\n",
    "    if isinstance(dim, str):\n",
    "        dim = [dim]\n",
    "\n",
    "    # Get the sizes of the bootstrap dimensions\n",
    "    sizes = None\n",
    "    for obj in objects:\n",
    "        try:\n",
    "            sizes = OrderedDict({d: obj.sizes[d] for d in dim})\n",
    "            break\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if sizes is None:\n",
    "        raise ValueError(\"At least one input object must contain all dimensions in dim\")\n",
    "\n",
    "    # Generate the random indices first so that we can be sure that each\n",
    "    # dask chunk uses the same indices. Note, I tried using random.seed()\n",
    "    # to achieve this but it was flaky\n",
    "    nested_indices = _nested_random_indices(sizes)  # Indices to resample all objects\n",
    "\n",
    "    # Need to expand the indices for broadcasting for each object separately\n",
    "    # as each object may have different dimensions\n",
    "    indices = []\n",
    "    input_core_dims = []\n",
    "    for obj in objects:\n",
    "        available_dims = [d for d in dim if d in obj.dims]\n",
    "        indices_to_expand = [nested_indices[key] for key in available_dims]\n",
    "\n",
    "        # Check that dimensions are nested\n",
    "        ndims = [i.ndim for i in indices_to_expand]\n",
    "        if ndims != list(range(1, len(ndims) + 1)):\n",
    "            raise ValueError(\"The dimensions of all inputs must be nested\")\n",
    "\n",
    "        indices.append(_expand_nested_random_indices(indices_to_expand))\n",
    "        input_core_dims.append(available_dims)\n",
    "\n",
    "    results = xr.apply_ufunc(\n",
    "        _bootstrap,\n",
    "        *objects,\n",
    "        kwargs=dict(\n",
    "            indices=indices,\n",
    "        ),\n",
    "        input_core_dims=input_core_dims,\n",
    "        output_core_dims=input_core_dims,\n",
    "        keep_attrs=True,\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[float] * len(input_core_dims),\n",
    "        dask_gufunc_kwargs=dict(output_sizes=sizes),\n",
    "    )\n",
    "\n",
    "    def _update_outer_dim_coords(ds, outer_dim_indices):\n",
    "        coords_to_update = [c for c in ds.coords if (dim[0] in ds[c].dims)]\n",
    "        for c in coords_to_update:\n",
    "            new_coord = ds[c].transpose(dim[0], ...)[outer_dim_indices]\n",
    "            ds = ds.assign_coords({c: (new_coord.dims, new_coord.values)})\n",
    "        return ds\n",
    "\n",
    "    if update_outer_dim_coords:\n",
    "        if len(objects) == 1:\n",
    "            return _update_outer_dim_coords(results, nested_indices[dim[0]])\n",
    "        else:\n",
    "            return tuple(\n",
    "                [\n",
    "                    _update_outer_dim_coords(result, nested_indices[dim[0]])\n",
    "                    for result in results\n",
    "                ]\n",
    "            )\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ec46d-f24b-423a-8637-2203cf85524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_bootstrap(*objects, dim, n_iterations):\n",
    "    \"\"\"\n",
    "    Repeatedly bootstrap the provided array across the specified dimension(s)\n",
    "    and stack the new arrays along a new \"iteration\" dimension. The\n",
    "    boostrapping is done in a nested manner. I.e. bootstrap the first provided\n",
    "    dimension, then for each bootstrapped sample along that dimenion, bootstrap\n",
    "    the second provided dimension, then for each bootstrapped sample along that\n",
    "    dimenion...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    objects : iterable of Datasets\n",
    "        The data to bootstrap. Multiple datasets can be passes to be\n",
    "        bootstrapped in the same way. Where multiple datasets are passed,\n",
    "        all datasets need not contain all bootstrapped dimensions. However,\n",
    "        because of the bootstrapping is applied in a nested manner, the\n",
    "        dimensions in all input objects must also be nested. E.g., for\n",
    "        `dim=['d1','d2','d3']` an object with dimensions 'd1' and 'd2' is\n",
    "        valid but an object with only dimension 'd2' is not.\n",
    "    dim : str or iterable of str\n",
    "        The dimension(s) to bootstrap in a nested manner.\n",
    "    n_iterations : int\n",
    "        The number of times to repeat the bootstrapping\n",
    "    \"\"\"\n",
    "    bootstraps = [\n",
    "        bootstrap(*objects, dim=dim, update_outer_dim_coords=False)\n",
    "        for _ in range(n_iterations)\n",
    "    ]\n",
    "    if len(objects) == 1:\n",
    "        return xr.concat(\n",
    "            bootstraps, dim=\"iteration\", coords=\"minimal\", compat=\"override\"\n",
    "        )\n",
    "    else:\n",
    "        return tuple(\n",
    "            [\n",
    "                xr.concat(b, dim=\"iteration\", coords=\"minimal\", compat=\"override\")\n",
    "                for b in zip(*bootstraps)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a727e-435b-4987-9b8a-437959fd4287",
   "metadata": {},
   "source": [
    "### Expand interations within ufunc\n",
    "This works great for small numbers of iterations but kills the kernel for n O(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "674c4fce-1766-4d74-9efb-125418ba60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def _n_nested_random_indexes(sizes, iterations):\n",
    "    \"\"\"\n",
    "    Returns indexes to randomly resample (with replacement) an array in a nested\n",
    "    manner. I.e. randomly resample the first dimension, then for each randomly\n",
    "    sampled element along that dimension, randomly resample the second dimension,\n",
    "    then for each randomly sampled element along that dimension, randomly resample\n",
    "    the third dimension etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sizes : OrderedDict\n",
    "        Dictionary with the names and sizes of the dimensions to resample\n",
    "    \"\"\"\n",
    "\n",
    "    shape = [s for s in sizes.values()]\n",
    "    indexes = OrderedDict()\n",
    "    for ax, key in enumerate(sizes.keys()):\n",
    "        indexes[key] = np.random.randint(0, shape[ax], shape[: ax + 1] + [iterations])\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def _expand_nested_random_indexes(indexes):\n",
    "    \"\"\"\n",
    "    Expand the dimensions of the nested input arrays so that they can be broadcast\n",
    "    and return a tuple that can be directly indexed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indexes : list of numpy arrays\n",
    "        List of numpy arrays of sequentially increasing dimension as output by the\n",
    "        function `nested_random_indexes`\n",
    "    \"\"\"\n",
    "    broadcast_ndim = indexes[-1].ndim\n",
    "    broadcast_indices = []\n",
    "    for i, index in enumerate(indexes):\n",
    "        expand_axes = list(range(i + 1, broadcast_ndim - 1))\n",
    "        broadcast_indices.append(np.expand_dims(index, axis=expand_axes))\n",
    "    return (..., *tuple(broadcast_indices))\n",
    "\n",
    "\n",
    "def bootstrap_iterations(*objects, dim, update_outer_dim_coords=True):\n",
    "    \"\"\"\n",
    "    Bootstrap the provided array across the specified dimension in a nested\n",
    "    manner. I.e. bootstrap the first provided dimension, then for each\n",
    "    bootstrapped sample along that dimenion, bootstrap the second provided\n",
    "    dimension, then for each bootstrapped sample along that dimenion...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    objects : iterable of Datasets\n",
    "        The data to bootstrap. Multiple datasets can be passes to be\n",
    "        bootstrapped in the same way. Where multiple datasets are passed,\n",
    "        all datasets need not contain all bootstrapped dimensions. However,\n",
    "        because of the bootstrapping is applied in a nested manner, the\n",
    "        dimensions in all input objects must also be nested. E.g., for\n",
    "        `dim=['d1','d2','d3']` an object with dimensions 'd1' and 'd2' is\n",
    "        valid but an object with only dimension 'd2' is not.\n",
    "    dim : str or iterable of str\n",
    "        The dimension(s) to bootstrap in a nested manner.\n",
    "    update_outer_dim_coords : boolean, optional\n",
    "        If True, the index coordinates of the outer (first) dimension in\n",
    "        dim and any non-index coordinates with this dimension are updated\n",
    "        to reflect the bootstrap shuffling along that dimension. Otherwise,\n",
    "        the data are shuffled, but the coordinates are left unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    iterations = 1000\n",
    "\n",
    "    def _bootstrap(*arrays, indexes):\n",
    "        \"\"\"Bootstrap the array(s) using the provided indexes\"\"\"\n",
    "        bootstrapped = [array[ind] for array, ind in zip(arrays, indexes)]\n",
    "        if len(bootstrapped) == 1:\n",
    "            return bootstrapped[0]\n",
    "        else:\n",
    "            return tuple(bootstrapped)\n",
    "\n",
    "    if isinstance(dim, str):\n",
    "        dim = [dim]\n",
    "\n",
    "    # Get the sizes of the bootstrap dimensions\n",
    "    sizes = None\n",
    "    for obj in objects:\n",
    "        try:\n",
    "            sizes = OrderedDict({d: obj.sizes[d] for d in dim})\n",
    "            break\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if sizes is None:\n",
    "        raise ValueError(\"At least one input object must contain all dimensions in dim\")\n",
    "\n",
    "    # Generate the random indices first so that we can be sure that each\n",
    "    # dask chunk uses the same indices. Note, I tried using random.seed()\n",
    "    # to achieve this but it was flaky\n",
    "    nested_indexes = _n_nested_random_indexes(\n",
    "        sizes, iterations\n",
    "    )  # Indices to resample all objects\n",
    "\n",
    "    # Need to expand the indexes for broadcasting for each object separately\n",
    "    # as each object may have different dimensions\n",
    "    indexes = []\n",
    "    input_core_dims = []\n",
    "    output_core_dims = []\n",
    "    for obj in objects:\n",
    "        available_dims = [d for d in dim if d in obj.dims]\n",
    "        indexes_to_expand = [nested_indexes[key] for key in available_dims]\n",
    "\n",
    "        # Check that dimensions are nested\n",
    "        ndims = [i.ndim for i in indexes_to_expand]\n",
    "        if ndims != list(range(2, len(ndims) + 2)):\n",
    "            raise ValueError(\"The dimensions of all inputs must be nested\")\n",
    "\n",
    "        indexes.append(_expand_nested_random_indexes(indexes_to_expand))\n",
    "        input_core_dims.append(available_dims)\n",
    "        output_core_dims.append(available_dims + [\"iteration\"])\n",
    "\n",
    "    results = xr.apply_ufunc(\n",
    "        _bootstrap,\n",
    "        *objects,\n",
    "        kwargs=dict(\n",
    "            indexes=indexes,\n",
    "        ),\n",
    "        input_core_dims=input_core_dims,\n",
    "        output_core_dims=output_core_dims,\n",
    "        dask=\"parallelized\",\n",
    "        dask_gufunc_kwargs=dict(output_sizes={\"iteration\": iterations}),\n",
    "        output_dtypes=[np.float32] * len(input_core_dims),\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "#     def update_outer_dim_coords(ds, outer_dim_indexes):\n",
    "#         coords_to_update = [c for c in ds.coords if (dim[0] in ds[c].dims)]\n",
    "#         for c in coords_to_update:\n",
    "#             new_coord = ds[c].transpose(dim[0], ...)[outer_dim_indexes]\n",
    "#             ds = ds.assign_coords({c: (new_coord.dims, new_coord.values)})\n",
    "#         return ds\n",
    "\n",
    "#     if update_outer_dim_coords:\n",
    "#         if len(objects) == 1:\n",
    "#             return update_outer_dim_coords(results, nested_indexes[dim[0]])\n",
    "#         else:\n",
    "#             return [\n",
    "#                 update_outer_dim_coords(result, nested_indexes[dim[0]])\n",
    "#                 for result in results\n",
    "#             ]\n",
    "#     else:\n",
    "#         return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928ea53-3eb1-4ad4-a210-c276bf7c322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nested_random_resample():\n",
    "    \"\"\"\n",
    "    Tests the function nested_random_resample\n",
    "\n",
    "    For each axis level of nested random sampling this checks that the elements\n",
    "    outer to the randomly sample axis are the same for each random sample. This\n",
    "    is only a check that the nesting hasn't not worked\n",
    "    \"\"\"\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    # Generate some test data with data that makes it location clear\n",
    "    shape = (6, 5, 4, 3, 2)\n",
    "    axes = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    n_axes = 2\n",
    "    test = np.zeros(shape, dtype=\"<U16\")\n",
    "    for i in itertools.product(*[range(i) for i in shape]):\n",
    "        test[i] = \"\".join([f\"{axes[j]}{i[j]}\" for j in range(len(i))])\n",
    "\n",
    "    # Randomly resample the test data\n",
    "    nested_indexes = _nested_random_indexes(dict(zip(axes, shape)))\n",
    "    indexes = _expand_nested_random_indexes([nested_indexes[k] for k in axes])\n",
    "    res = test[indexes]\n",
    "\n",
    "    # Check that the nesting hasn't not worked\n",
    "    for a in range(-n_axes, 0):\n",
    "        # Look at a random location for the not sampled axes\n",
    "        idx = [np.random.randint(0, i) for i in res.shape[:a]]\n",
    "        idx.append(slice(None))\n",
    "\n",
    "        for element_idx in itertools.product(*[range(i) for i in res.shape[a:][1:]]):\n",
    "            to_check = res[tuple(idx + list(element_idx))]\n",
    "            identical_elements = [s[: 2 * (res.ndim + a)] for s in to_check]\n",
    "            assert len(set(identical_elements)) == 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (forecast_analysis)",
   "language": "python",
   "name": "forecast_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
