{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301db601-2d0d-4c9c-adee-e396968d6a1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploring CAFE-f6 bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffd7d73-711e-4197-b9f7-4e52b34aea08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x14c4c34aebe0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import dask\n",
    "\n",
    "import cftime\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dask.config.set(**{\"array.slicing.split_large_chunks\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4300ac-96d7-4006-a52b-b2041750fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fdd3cb-db40-4c00-a466-fa5adfefd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1fda51-83c5-4b00-8d15-14eba578e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x14c4c371c8e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354960b6-b1aa-4cfb-86b3-6b50360f4bef",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b23f2e9-85fa-435c-a9f0-60efa6bee6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xv83/users/ds0092/software/miniconda3/envs/cafe-f6_analysis/lib/python3.9/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "walltime = \"04:00:00\"\n",
    "cores = 48\n",
    "memory = \"192GB\"\n",
    "cluster = PBSCluster(\n",
    "    processes=1,\n",
    "    walltime=str(walltime),\n",
    "    cores=cores,\n",
    "    memory=str(memory),\n",
    "    job_extra=[\n",
    "        \"-l ncpus=\" + str(cores),\n",
    "        \"-l mem=\" + str(memory),\n",
    "        \"-P xv83\",\n",
    "        \"-l jobfs=100GB\",\n",
    "        \"-l storage=gdata/xv83\",\n",
    "    ],\n",
    "    local_directory=\"$PBS_JOBFS\",\n",
    "    # env_extra=['export MALLOC_TRIM_THRESHOLD_=\"0\"'],\n",
    "    header_skip=[\"select\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae609b48-bdf7-43e0-b95a-a0184480ae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-f1b9d24b-8557-11ec-8170-54b203878aff</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://10.6.24.71:8787/status\" target=\"_blank\">http://10.6.24.71:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">18070d33</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://10.6.24.71:8787/status\" target=\"_blank\">http://10.6.24.71:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-12851b70-045a-4979-865b-33b82ed4df6b</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.24.71:43139\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.6.24.71:8787/status\" target=\"_blank\">http://10.6.24.71:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.24.71:43139' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scale(jobs=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032dc35-6e98-486f-a838-9435d7fe2281",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare some data - CAFE hindcasts\n",
    "Use only the November forecasts, due to issue with changing executable for May forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980d7e29-32cb-4d9c-aa57-409c791618e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_CAFEf6_monthly_to_annual(ds):\n",
    "    \"\"\"Preprocessing steps for CAFE-f6 data\"\"\"\n",
    "\n",
    "    ds = utils.round_to_start_of_month(ds, dim=\"time\")\n",
    "    ds = utils.convert_time_to_lead(ds)\n",
    "\n",
    "    ds = utils.coarsen_monthly_to_annual(ds, dim=\"lead\")\n",
    "\n",
    "    # Truncate lats so that forecasts run on different systems can be stacked\n",
    "    if \"lat\" in ds.dims:\n",
    "        ds = utils.truncate_latitudes(ds)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cccc88f-2af6-47bd-81ad-c620355a6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(ds, area, dim=[\"lat\", \"lon\"]):\n",
    "    return ds.weighted(area).mean(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9380d1-89fa-4495-91b8-89569075dc41",
   "metadata": {},
   "source": [
    "### Atmospheric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2e2cc3-cc59-48e7-895a-7ecfe88f9642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE-f6\"\n",
    "realm = \"atmos_isobaric_month.zarr.zip\"\n",
    "variable = {\"t_ref\": 1, \"precip\": 86400}  # Including scale factor\n",
    "\n",
    "files = sorted(glob.glob(f\"{data_dir}/c5-d60-pX-f6-????11??/{realm}\"))\n",
    "\n",
    "f6_hcst_atmos = xr.open_mfdataset(\n",
    "    files,\n",
    "    compat=\"override\",\n",
    "    preprocess=preprocess_CAFEf6_monthly_to_annual,\n",
    "    engine=\"zarr\",\n",
    "    coords=\"minimal\",\n",
    "    parallel=True,\n",
    ")[variable.keys()]\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    f6_hcst_atmos[k] = f6_hcst_atmos[k] * v\n",
    "\n",
    "cafe_atmos_area = f6_hcst_atmos[\"area\"]\n",
    "\n",
    "# Focus on global mean for now\n",
    "f5_2020_atmos = f6_hcst_atmos.sel(init=\"2020\").isel(ensemble=range(10))\n",
    "f6_hcst = global_mean(f6_hcst_atmos.mean(\"ensemble\"), cafe_atmos_area).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0dad57-3d6c-45c8-bb5c-0d8cad321f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE-f5/NOV/\"\n",
    "realm = \"atmos_isobaric_month.zarr.zip\"\n",
    "variable = {\"t_ref\": 1, \"precip\": 86400}  # Including scale factor\n",
    "\n",
    "f5_hcst_atmos = xr.open_dataset(f\"{data_dir}{realm}\", engine=\"zarr\", chunks={})[\n",
    "    variable.keys()\n",
    "]\n",
    "f5_hcst_atmos = f5_hcst_atmos.rename({\"init_date\": \"init\", \"lead_time\": \"lead\"})\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    f5_hcst_atmos[k] = f5_hcst_atmos[k] * v\n",
    "\n",
    "f5_hcst_atmos = utils.coarsen_monthly_to_annual(f5_hcst_atmos, dim=\"lead\")\n",
    "f5_hcst_atmos = utils.round_to_start_of_month(f5_hcst_atmos, dim=[\"init\", \"time\"])\n",
    "f5_hcst_atmos = xr.concat((f5_hcst_atmos, f5_2020_atmos), dim=\"init\")\n",
    "\n",
    "# Focus on global mean for now\n",
    "f5_hcst = global_mean(f5_hcst_atmos, cafe_atmos_area).mean(\"ensemble\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d534286-1b34-44b0-b0ab-e66f151866b2",
   "metadata": {},
   "source": [
    "### Ocean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244f40a-c58d-4569-8f36-4782b9710bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE-f6\"\n",
    "realm = \"ocean_month.zarr.zip\"\n",
    "variable = {\"sst\": 1}  # Including scale factor\n",
    "\n",
    "files = sorted(glob.glob(f\"{data_dir}/c5-d60-pX-f6-????11??/{realm}\"))\n",
    "\n",
    "f6_hcst_ocean = xr.open_mfdataset(\n",
    "    files,\n",
    "    compat=\"override\",\n",
    "    preprocess=preprocess_CAFEf6_monthly_to_annual,\n",
    "    engine=\"zarr\",\n",
    "    coords=\"minimal\",\n",
    "    parallel=True,\n",
    ")[variable.keys()]\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    f6_hcst_ocean[k] = f6_hcst_ocean[k] * v\n",
    "\n",
    "cafe_ocean_area = f6_hcst_ocean[\"area_t\"]\n",
    "\n",
    "# Focus on global mean for now\n",
    "f5_2020_ocean = f6_hcst_ocean.sel(init=\"2020\").isel(ensemble=range(10))\n",
    "f6_hcst = xr.merge(\n",
    "    [\n",
    "        f6_hcst,\n",
    "        global_mean(\n",
    "            f6_hcst_ocean.mean(\"ensemble\"), cafe_ocean_area, [\"xt_ocean\", \"yt_ocean\"]\n",
    "        ).compute(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfad9fb-1bba-45f5-843e-0fc460e293ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE-f5/NOV/\"\n",
    "realm = \"ocean_month.zarr.zip\"\n",
    "variable = {\"sst\": 1}  # Including scale factor\n",
    "\n",
    "f5_hcst_ocean = xr.open_dataset(f\"{data_dir}{realm}\", engine=\"zarr\", chunks={})[\n",
    "    variable.keys()\n",
    "]\n",
    "f5_hcst_ocean = f5_hcst_ocean.rename({\"init_date\": \"init\", \"lead_time\": \"lead\"})\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    f5_hcst_ocean[k] = f5_hcst_ocean[k] * v\n",
    "\n",
    "f5_hcst_ocean = utils.coarsen_monthly_to_annual(f5_hcst_ocean, dim=\"lead\")\n",
    "f5_hcst_ocean = utils.round_to_start_of_month(f5_hcst_ocean, dim=[\"init\", \"time\"])\n",
    "f5_hcst_ocean = xr.concat((f5_hcst_ocean, f5_2020_ocean), dim=\"init\")\n",
    "\n",
    "# Focus on global mean for now\n",
    "f5_hcst = xr.merge(\n",
    "    [\n",
    "        f5_hcst,\n",
    "        global_mean(f5_hcst_ocean, cafe_ocean_area, [\"xt_ocean\", \"yt_ocean\"])\n",
    "        .mean(\"ensemble\")\n",
    "        .compute(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e95ee-9c59-4fb3-a1f2-367314689f02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare some data - CAFE60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5eb47-553b-4a20-b7f6-636a41c39567",
   "metadata": {},
   "source": [
    "### Atmospheric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2186a-3c2f-40db-bc30-ceeb862b54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE60v1/\"\n",
    "realm = \"atmos_isobaric_month.zarr.zip\"\n",
    "variable = {\"t_ref\": 1, \"precip\": 86400}\n",
    "\n",
    "cafe_60_atmos = xr.open_dataset(f\"{data_dir}{realm}\", engine=\"zarr\", chunks={})[\n",
    "    variable.keys()\n",
    "]\n",
    "cafe_60_atmos = utils.truncate_latitudes(cafe_60_atmos)\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    cafe_60_atmos[k] = cafe_60_atmos[k] * v\n",
    "\n",
    "cafe_60_atmos = utils.coarsen_monthly_to_annual(\n",
    "    cafe_60_atmos, f5_hcst.init[0], dim=\"time\"\n",
    ")\n",
    "cafe_60_atmos = utils.round_to_start_of_month(cafe_60_atmos, dim=\"time\")\n",
    "\n",
    "# Focus on global mean for now\n",
    "cafe_60 = global_mean(cafe_60_atmos, cafe_atmos_area).mean(\"ensemble\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d4d82-1df8-408b-b320-93e5c1fc960a",
   "metadata": {},
   "source": [
    "### Ocean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b3c11-146d-4d96-95f9-f5e50063c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/dcfp/CAFE60v1/\"\n",
    "realm = \"ocean_month.zarr.zip\"\n",
    "variable = {\"sst\": 1}\n",
    "\n",
    "cafe_60_ocean = xr.open_dataset(f\"{data_dir}{realm}\", engine=\"zarr\", chunks={})[\n",
    "    variable.keys()\n",
    "]\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    cafe_60_ocean[k] = cafe_60_ocean[k] * v\n",
    "\n",
    "cafe_60_ocean = utils.coarsen_monthly_to_annual(\n",
    "    cafe_60_ocean, f5_hcst.init[0], dim=\"time\"\n",
    ")\n",
    "cafe_60_ocean = utils.round_to_start_of_month(cafe_60_ocean, dim=\"time\")\n",
    "\n",
    "# Focus on global mean for now\n",
    "cafe_60 = xr.merge(\n",
    "    [\n",
    "        cafe_60,\n",
    "        global_mean(cafe_60_ocean, cafe_ocean_area, [\"xt_ocean\", \"yt_ocean\"])\n",
    "        .mean(\"ensemble\")\n",
    "        .compute(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b7bc1-44fd-4e3e-a467-2a0b0ea15f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare some data - CAFE historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97e09d-7d47-4e42-b6c9-6a9b80b41eb5",
   "metadata": {},
   "source": [
    "### Atmospheric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8add78-25ae-4bb1-ab58-ad1acf5356cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/users/ds0092/data/CAFE/historical/WIP\"\n",
    "realm = \"atmos_isobaric_month.zarr.zip\"\n",
    "variable = {\"t_ref\": 1, \"precip\": 86400}  # Including scale factor\n",
    "\n",
    "cafe_hist_atmos = utils.truncate_latitudes(\n",
    "    xr.open_zarr(f\"{data_dir}/c5-d60-pX-hist-19601101/ZARR/{realm}\")\n",
    ")[variable.keys()]\n",
    "cafe_ctrl_atmos = utils.truncate_latitudes(\n",
    "    xr.open_zarr(f\"{data_dir}/c5-d60-pX-ctrl-19601101/ZARR/{realm}\")\n",
    ")[variable.keys()]\n",
    "\n",
    "cafe_ctrl_atmos_drift = (\n",
    "    cafe_ctrl_atmos.mean(\"ensemble\")\n",
    "    .groupby(\"time.month\")\n",
    "    .map(lambda x: x - x.mean([\"time\"]))\n",
    ")\n",
    "cafe_hist_atmos = cafe_hist_atmos - cafe_ctrl_atmos_drift\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    cafe_hist_atmos[k] = cafe_hist_atmos[k] * v\n",
    "\n",
    "cafe_hist_atmos = utils.round_to_start_of_month(cafe_hist_atmos, dim=\"time\")\n",
    "cafe_hist_atmos = utils.coarsen_monthly_to_annual(cafe_hist_atmos, f5_hcst.init[0])\n",
    "\n",
    "# Focus on global mean for now\n",
    "cafe_hist = global_mean(cafe_hist_atmos, cafe_atmos_area).mean(\"ensemble\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcfc5e-bf71-4f39-b49f-dca75ef8367a",
   "metadata": {},
   "source": [
    "### Ocean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef304c-55e6-487e-a763-e5a877ae9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/g/data/xv83/users/ds0092/data/CAFE/historical/WIP\"\n",
    "realm = \"ocean_month.zarr.zip\"\n",
    "variable = {\"sst\": 1}  # Including scale factor\n",
    "\n",
    "cafe_hist_ocean = utils.truncate_latitudes(\n",
    "    xr.open_zarr(f\"{data_dir}/c5-d60-pX-hist-19601101/ZARR/{realm}\")\n",
    ")[variable.keys()]\n",
    "cafe_ctrl_ocean = utils.truncate_latitudes(\n",
    "    xr.open_zarr(f\"{data_dir}/c5-d60-pX-ctrl-19601101/ZARR/{realm}\")\n",
    ")[variable.keys()]\n",
    "\n",
    "cafe_ctrl_ocean_drift = (\n",
    "    cafe_ctrl_ocean.mean(\"ensemble\")\n",
    "    .groupby(\"time.month\")\n",
    "    .map(lambda x: x - x.mean([\"time\"]))\n",
    ")\n",
    "cafe_hist_ocean = cafe_hist_ocean - cafe_ctrl_ocean_drift\n",
    "\n",
    "# Rescale variables\n",
    "for k, v in variable.items():\n",
    "    cafe_hist_ocean[k] = cafe_hist_ocean[k] * v\n",
    "\n",
    "cafe_hist_ocean = utils.round_to_start_of_month(cafe_hist_ocean, dim=\"time\")\n",
    "cafe_hist_ocean = utils.coarsen_monthly_to_annual(cafe_hist_ocean, f5_hcst.init[0])\n",
    "\n",
    "# Focus on global mean for now\n",
    "cafe_hist = xr.merge(\n",
    "    [\n",
    "        cafe_hist,\n",
    "        global_mean(cafe_hist_ocean, cafe_ocean_area, [\"xt_ocean\", \"yt_ocean\"])\n",
    "        .mean(\"ensemble\")\n",
    "        .compute(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722115f4-a66e-4276-bfb0-59da9f07e989",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare some data - JRA55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547c8fe-f7b4-4bca-81ed-b8bce1129adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/g/data/xv83/reanalyses/JRA55/surface_month_cafe-grid.zarr.zip\"\n",
    "variable = [\"TMP_GDS0_HTGL\", \"TPRAT_GDS0_SFC\"]\n",
    "\n",
    "jra55 = utils.truncate_latitudes(\n",
    "    xr.open_zarr(\n",
    "        path,\n",
    "        use_cftime=True,\n",
    "    )\n",
    ")[variable]\n",
    "\n",
    "jra55 = jra55.rename(\n",
    "    {\n",
    "        \"initial_time0_hours\": \"time\",\n",
    "        \"TMP_GDS0_HTGL\": \"t_ref\",\n",
    "        \"TPRAT_GDS0_SFC\": \"precip\",\n",
    "    }\n",
    ")\n",
    "# Force to Julian calendar\n",
    "jra55 = jra55.assign_coords(\n",
    "    {\n",
    "        \"time\": xr.cftime_range(\n",
    "            start=jra55.time[0].item().strftime(),\n",
    "            end=jra55.time[-1].item().strftime(),\n",
    "            freq=\"MS\",\n",
    "            calendar=\"julian\",\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process annual means to match hcst dataset\n",
    "jra55 = utils.coarsen_monthly_to_annual(jra55, f5_hcst.init[0])\n",
    "\n",
    "# Focus on global mean for now\n",
    "obs = global_mean(jra55, cafe_atmos_area).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fc09c-7bc0-41da-8c16-38f150106992",
   "metadata": {},
   "source": [
    "# Prepare some data - HadISST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fcc61-a21a-43d4-98bb-36cbc3155380",
   "metadata": {},
   "outputs": [],
   "source": [
    "had = xr.open_dataset(\n",
    "    \"/g/data/xv83/reanalyses/HadISST/ocean_month.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    use_cftime=True,\n",
    ")\n",
    "had = had.where(had > -1000)[\"sst\"].rename({\"longitude\": \"lon\", \"latitude\": \"lat\"})\n",
    "\n",
    "had = utils.round_to_start_of_month(had, dim=\"time\")\n",
    "\n",
    "# Force to Julian calendar\n",
    "had = had.assign_coords(\n",
    "    {\n",
    "        \"time\": xr.cftime_range(\n",
    "            start=had.time[0].item().strftime(),\n",
    "            end=had.time[-1].item().strftime(),\n",
    "            freq=\"MS\",\n",
    "            calendar=\"julian\",\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "had = utils.coarsen_monthly_to_annual(had, f5_hcst.init[0])\n",
    "\n",
    "# Focus on global mean for now\n",
    "had_area = (\n",
    "    utils.estimate_cell_areas(had).broadcast_like(had, exclude=[\"time\"]).fillna(0)\n",
    ")\n",
    "obs = xr.merge([obs, global_mean(had, had_area).compute()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4ae3b-49cf-437e-843e-1b6de2f5d6c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove the biases\n",
    "\n",
    "### Calculate the biases from the f6 climatology over the max consistent period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c1942-a0ca-4419-99b6-47c75ced4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_mean(hcst, obs):\n",
    "    hcst_clim = hcst.mean(\"init\")\n",
    "    obs_clim = obs.mean(\"time\")\n",
    "    return hcst_clim - obs_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503a30e-4bf8-4ec8-a1af-6a2f08fe111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = [cftime.DatetimeJulian(1991, 10, 1), cftime.DatetimeJulian(2020, 10, 1)]\n",
    "\n",
    "bias = bias_mean(\n",
    "    f6_hcst.where((f6_hcst.time >= period[0]) & (f6_hcst.time <= period[1])),\n",
    "    obs.where((obs.time >= period[0]) & (obs.time <= period[1])),\n",
    ")\n",
    "\n",
    "\n",
    "f6_hcst_bc = f6_hcst - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de117977-fdd0-4a92-bb0b-c83acce2ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hindcasts(hcsts, hcsts_bc):\n",
    "    from matplotlib.pyplot import cm\n",
    "    from matplotlib.dates import date2num\n",
    "\n",
    "    def shading(ax):\n",
    "        trans = cftime.DatetimeJulian(1992, 1, 1)\n",
    "        end = cftime.DatetimeJulian(2040, 1, 1)\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.fill_between(\n",
    "            [trans, end],\n",
    "            [ylim[1], ylim[1]],\n",
    "            [ylim[0], ylim[0]],\n",
    "            color=[0.9, 0.9, 0.9],\n",
    "        )\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    n_vars = len(hcsts.data_vars)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, n_vars * 4))\n",
    "    axs = fig.subplots(n_vars, 1, sharex=True)\n",
    "    if n_vars == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for a, var in enumerate(hcsts.data_vars):\n",
    "        color = cm.autumn(np.linspace(0, 0.9, len(hcsts[var].init)))\n",
    "        color_bc = cm.winter(np.linspace(0, 0.9, len(hcsts[var].init)))\n",
    "        for idx, (i, c, c_bc) in enumerate(zip(hcsts[var].init, color, color_bc)):\n",
    "            if idx == 0:\n",
    "                label = \"CAFE-f6 raw\"\n",
    "                label_bc = \"CAFE-f6 bias corrected\"\n",
    "            else:\n",
    "                label = label_bc = \"_nolabel_\"\n",
    "\n",
    "            hcst = hcsts[var].sel(init=i)\n",
    "            axs[a].plot(hcst.time[0], hcst[0], color=c, marker=\"o\", label=\"_nolabel_\")\n",
    "            axs[a].plot(hcst.time, hcst, color=c, linestyle=\"-\", label=label)\n",
    "\n",
    "            hcst_bc = hcsts_bc[var].sel(init=i)\n",
    "            axs[a].plot(\n",
    "                hcst_bc.time[0], hcst_bc[0], color=c_bc, marker=\"o\", label=\"_nolabel_\"\n",
    "            )\n",
    "            axs[a].plot(\n",
    "                hcst_bc.time, hcst_bc, color=c_bc, linestyle=\"-\", label=label_bc\n",
    "            )\n",
    "\n",
    "        axs[a].plot(obs.time, obs[var], color=\"black\", label=\"Observations\")\n",
    "        axs[a].plot(\n",
    "            cafe_60.time, cafe_60[var], color=\"black\", linestyle=\"--\", label=\"CAFE60v1\"\n",
    "        )\n",
    "        axs[a].plot(\n",
    "            cafe_hist.time, cafe_hist[var], color=\"grey\", label=\"CAFE-historical\"\n",
    "        )\n",
    "\n",
    "        ticks = xr.cftime_range(\n",
    "            start=\"1981-01-01\", end=\"2032-01-01\", freq=\"2AS\", calendar=\"julian\"\n",
    "        )\n",
    "        axs[a].set_xticks(ticks.values)\n",
    "        axs[a].set_xticklabels(ticks.year)\n",
    "        axs[a].set_xlim(\n",
    "            cftime.DatetimeJulian(1981, 1, 1), cftime.DatetimeJulian(2032, 1, 1)\n",
    "        )\n",
    "        axs[a].set_ylabel(hcsts[var].attrs[\"long_name\"])\n",
    "        axs[a].grid()\n",
    "        if a == 0:\n",
    "            axs[a].legend()\n",
    "        if a == (n_vars - 1):\n",
    "            axs[a].set_xlabel(\"year\")\n",
    "        else:\n",
    "            axs[a].set_xlabel(\"\")\n",
    "\n",
    "        shading(axs[a])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8127c1d-f185-4849-80ec-c9a325611474",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43dd89-2eab-4f83-8864-cb5d22b25506",
   "metadata": {},
   "source": [
    "### That obviously has quite a large step around 1992 due to the change to CAFE60's bias-correction scheme.\n",
    "\n",
    "### What about if we calculate anomalies for pre and post 1992 separately? Let's use CAFE-f5 so that we can use the same length period for bias correction pre and post the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d655f2-7007-4329-9812-df409b143288",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_year = 1992\n",
    "\n",
    "period_1 = [\n",
    "    cftime.DatetimeJulian(1973, 10, 1),\n",
    "    cftime.DatetimeJulian(1992, 10, 1),\n",
    "]  # 20 years, using initial dates < 1992\n",
    "period_2 = [\n",
    "    cftime.DatetimeJulian(2002, 10, 1),\n",
    "    cftime.DatetimeJulian(2021, 10, 1),\n",
    "]  # 20 years, using initial dates >= 1992\n",
    "\n",
    "bias_1 = bias_mean(\n",
    "    f5_hcst.where((f5_hcst.time >= period_1[0]) & (f5_hcst.time <= period_1[1])),\n",
    "    obs.where((obs.time >= period_1[0]) & (obs.time <= period_1[1])),\n",
    ")\n",
    "\n",
    "bias_2 = bias_mean(\n",
    "    f5_hcst.where((f5_hcst.time >= period_2[0]) & (f5_hcst.time <= period_2[1])),\n",
    "    obs.where((obs.time >= period_2[0]) & (obs.time <= period_2[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc1 = f6_hcst.sel(init=slice(None, str(transition_year - 1))) - bias_1\n",
    "f6_hcst_bc2 = f6_hcst.sel(init=slice(str(transition_year), None)) - bias_2\n",
    "f6_hcst_bc = xr.concat((f6_hcst_bc1, f6_hcst_bc2), dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347df59d-8ab2-4b73-aeaa-5c66471bdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 8))\n",
    "\n",
    "x = np.arange(len(f5_hcst.lead) + 1)\n",
    "y = np.arange(1, len(f5_hcst.init) + 2) - 0.5\n",
    "c = f5_hcst[\"sst\"].transpose(\"init\", \"lead\")\n",
    "im = ax.pcolor(x, y, c)\n",
    "\n",
    "ax.set_xticks(np.arange(len(f5_hcst.lead)) + 0.5)\n",
    "ax.set_xticklabels(f5_hcst.lead.values)\n",
    "ax.set_yticks(np.arange(1, len(f5_hcst.init) + 1, 2))\n",
    "ax.set_yticklabels(f5_hcst.init.dt.year.values[::2])\n",
    "\n",
    "\n",
    "def hatch(mask, color):\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    for j, i in np.column_stack(np.where(mask)):\n",
    "        ax.add_patch(\n",
    "            mpatches.Rectangle(\n",
    "                (i, j + 0.5),\n",
    "                1,\n",
    "                1,\n",
    "                fill=False,\n",
    "                linewidth=0,\n",
    "                snap=False,\n",
    "                color=color,\n",
    "                hatch=\"///\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "mask = xr.ones_like(f5_hcst[\"t_ref\"]).where(\n",
    "    (f5_hcst.time >= period_1[0]) & (f5_hcst.time <= period_1[1]),\n",
    "    0,\n",
    ")\n",
    "hatch(mask, \"c\")\n",
    "mask = xr.ones_like(f5_hcst[\"t_ref\"]).where(\n",
    "    (f5_hcst.time >= period_2[0]) & (f5_hcst.time <= period_2[1]),\n",
    "    0,\n",
    ")\n",
    "hatch(mask, \"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93295f8-d3df-4202-9825-90f3670938b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b6d2a-355e-4d51-a52b-a1d7d66abd1e",
   "metadata": {},
   "source": [
    "### Looks okay for `t_ref` and `sst` but not `precip`... What about if we do the same thing but don't limit ourselves to a consistent period at each lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52948bb4-8e7a-43ee-99ba-e051fa79dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_year = 1992\n",
    "\n",
    "period_1 = slice(\n",
    "    cftime.DatetimeJulian(1963, 11, 1),\n",
    "    cftime.DatetimeJulian(1991, 11, 1),\n",
    ")  # 28 years\n",
    "period_2 = slice(\n",
    "    cftime.DatetimeJulian(1992, 11, 1),\n",
    "    cftime.DatetimeJulian(2020, 11, 1),\n",
    ")  # 28 years\n",
    "\n",
    "f5_period_1 = f5_hcst.sel(init=period_1)\n",
    "bias_1 = []\n",
    "for l in f5_period_1.lead:\n",
    "    ts = f5_period_1.sel(lead=l).swap_dims({\"init\": \"time\"})\n",
    "    bias_1.append((ts - obs).mean(\"time\").expand_dims({\"lead\": [l]}))\n",
    "bias_1 = xr.concat(bias_1, dim=\"lead\")\n",
    "\n",
    "f5_period_2 = f5_hcst.sel(init=period_2)\n",
    "bias_2 = []\n",
    "for l in f5_period_2.lead:\n",
    "    ts = f5_period_2.sel(lead=l).swap_dims({\"init\": \"time\"})\n",
    "    bias_2.append((ts - obs).mean(\"time\").expand_dims({\"lead\": [l]}))\n",
    "bias_2 = xr.concat(bias_2, dim=\"lead\")\n",
    "\n",
    "f6_hcst_bc1 = f6_hcst.sel(init=slice(None, str(transition_year - 1))) - bias_1\n",
    "f6_hcst_bc2 = f6_hcst.sel(init=slice(str(transition_year), None)) - bias_2\n",
    "f6_hcst_bc = xr.concat((f6_hcst_bc1, f6_hcst_bc2), dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537fab1-ce41-42dc-993e-5f64fd366399",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354976c-a68e-4290-b34f-d42677801776",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Still not great... What about correcting for the biases on a sliding window basis, using the previous 12 years of data?\n",
    "\n",
    "e.g. \n",
    "- for the 1981 forecast, biases are calculated over the period 1970-1981 at all leads\n",
    "- for the 2020 forecast, biases are calculated over the period 2009-2020 at all leads \n",
    "\n",
    "This is a fair approach, but it will have to use the f5 forecasts to calculate the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7b131-96e4-4fe0-a884-81d0a9bd7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years = 12\n",
    "\n",
    "objs = []\n",
    "for init in f6_hcst.init:\n",
    "    hcst = f6_hcst.sel(init=[init.item()])\n",
    "\n",
    "    # Calculate the bias\n",
    "    clim_range = [\n",
    "        hcst.get_index(\"init\").shift(-(12 * n_years), \"MS\").item(),\n",
    "        hcst.get_index(\"init\").item(),\n",
    "    ]\n",
    "    bias = bias_mean(\n",
    "        f5_hcst.where(\n",
    "            (f5_hcst.time >= clim_range[0]) & (f5_hcst.time <= clim_range[1])\n",
    "        ),\n",
    "        obs.where((obs.time >= clim_range[0]) & (obs.time <= clim_range[1])),\n",
    "    )\n",
    "\n",
    "    objs.append(hcst - bias)\n",
    "\n",
    "f6_hcst_bc = xr.concat(objs, dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7a755-8a67-4e4a-bd6d-fd3aadfe07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6565243-4e22-4bbb-854c-e0eec46ede93",
   "metadata": {},
   "source": [
    "### What about doing this in an unfair way, selecting the period based on initial date alone?\n",
    "This approach uses observations from the future to perform the bias correction at non-zero leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68ccc7-37b6-4eb0-b358-4cca251fb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years = 20\n",
    "\n",
    "objs = []\n",
    "for init in f6_hcst.init:\n",
    "    hcst = f6_hcst.sel(init=[init.item()])\n",
    "\n",
    "    init_range = slice(\n",
    "        hcst.get_index(\"init\").shift(-(12 * (n_years - 1)), \"MS\").item(),\n",
    "        hcst.get_index(\"init\").item(),\n",
    "    )\n",
    "    f5_period = f5_hcst.sel(init=init_range)\n",
    "    bias = []\n",
    "    for l in f5_period.lead:\n",
    "        ts = f5_period.sel(lead=l).swap_dims({\"init\": \"time\"})\n",
    "        bias.append((ts - obs).mean(\"time\").expand_dims({\"lead\": [l]}))\n",
    "    bias = xr.concat(bias, dim=\"lead\")\n",
    "\n",
    "    objs.append(hcst - bias)\n",
    "\n",
    "f6_hcst_bc = xr.concat(objs, dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2ff93-492c-483d-8caa-f024b14c2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf538d0-20c1-45cf-b2f0-9162a3c692b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What about fitting an exponential?\n",
    "Of the form $D(l>0) = D(l=0) \\exp(-A l)$ where $D = F - H$ is the deviation between the forecast, $F$, and the historical run, $H$; and $l$ is the lead time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6f727-ad93-42f7-bd21-e1f50956d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"t_ref\"  # Only works on DataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dec19-7073-4c89-88ac-da36accdee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in f6_hcst.init:\n",
    "    hcst = f6_hcst.sel(init=i).swap_dims({\"lead\": \"time\"})\n",
    "    res.append((hcst - cafe_hist)[var].swap_dims({\"time\": \"lead\"}))\n",
    "\n",
    "f6_D = xr.concat(res, dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ba769-7d1b-4ecc-bf01-43d5b68758b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import leastsq\n",
    "\n",
    "\n",
    "def multiple_reg(x, y, f, const, params0, **kwargs):\n",
    "    \"\"\"Do same non-linear regression on multiple curves\"\"\"\n",
    "\n",
    "    def leastsq_func(params, *args):\n",
    "        x, y = args[:2]\n",
    "        const = args[2:]\n",
    "        yfit = []\n",
    "        for i in range(len(x)):\n",
    "            yfit = np.append(yfit, f(x[i], *const[i], *params))\n",
    "        return y - yfit\n",
    "\n",
    "    # turn const into 2d-array if 1d is given\n",
    "    const = np.asarray(const)\n",
    "    if len(const.shape) < 2:\n",
    "        const = np.atleast_2d(const).T\n",
    "\n",
    "    # ensure that y is flat and x is nested\n",
    "    if hasattr(y[0], \"__len__\"):\n",
    "        y = [item for sublist in y for item in sublist]\n",
    "    if not hasattr(x[0], \"__len__\"):\n",
    "        x = np.tile(x, (len(const), 1))\n",
    "    x_ = [item for sublist in x for item in sublist]\n",
    "    assert len(x_) == len(y)\n",
    "\n",
    "    # collect all arguments in a tuple\n",
    "    y = np.asarray(y)\n",
    "    args = [x, y] + list(const)\n",
    "    args = tuple(args)  # doesn't work if args is a list!!\n",
    "\n",
    "    return leastsq(leastsq_func, params0, args=args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ce5b0-8062-4164-b946-b0ce1583ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, D0, A, B):\n",
    "    return B * D0 * np.exp(-A * x)  # B * D0 + B * D0 * np.tanh(-A * x)  #\n",
    "\n",
    "\n",
    "p, _ = multiple_reg(\n",
    "    f6_D.lead.values[1:], f6_D.values[:, 1:], fit, f6_D.values[:, 0], [0.1, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639b7d4-36b4-4b24-88fa-d8fba3b78704",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6_hcst_bc = []\n",
    "f6_hcst_fit = []\n",
    "for i in f6_D.init:\n",
    "    f6_D_ts = f6_D.sel(init=i).swap_dims({\"lead\": \"time\"})\n",
    "    f6_hcst_ts = f6_hcst.sel(init=i).swap_dims({\"lead\": \"time\"})\n",
    "    D_fit = fit(f6_D_ts.lead, f6_D_ts.values[0], p[0], p[1])\n",
    "    D_fit = xr.zeros_like(f6_hcst_ts) + D_fit\n",
    "    f6_hcst_bc.append((f6_hcst_ts - D_fit).swap_dims({\"time\": \"lead\"}))\n",
    "    f6_hcst_fit.append((D_fit + cafe_hist).swap_dims({\"time\": \"lead\"}))\n",
    "\n",
    "f6_hcst_bc = xr.concat(f6_hcst_bc, dim=\"init\")\n",
    "f6_hcst_fit = xr.concat(f6_hcst_fit, dim=\"init\")\n",
    "\n",
    "period = [cftime.DatetimeJulian(1991, 10, 1), cftime.DatetimeJulian(2020, 10, 1)]\n",
    "\n",
    "f6_clim = f6_hcst_bc.where(\n",
    "    (f6_hcst_bc.time >= period[0]) & (f6_hcst_bc.time <= period[1])\n",
    ").mean(\"init\")\n",
    "jra_clim = obs.where((obs.time >= period[0]) & (obs.time <= period[1])).mean(\"time\")\n",
    "bias = (f6_clim - jra_clim).mean(\"lead\")\n",
    "\n",
    "f6_hcst_bc = f6_hcst_bc - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7a9cb-7d9f-4284-b057-7c73ea06764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst[[var]], f6_hcst_bc[[var]])\n",
    "\n",
    "for i in f6_hcst_fit.init:\n",
    "    plot_fit = f6_hcst_fit[var].sel(init=i).swap_dims({\"lead\": \"time\"})\n",
    "    plt.plot(plot_fit.time, plot_fit, color=\"k\", linestyle=\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e92913-e433-47de-8c1f-e4abceb90c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Perhaps there is a clever way to utilize the historical run in the bias correction, but this is not it... \n",
    "\n",
    "### What about splitting about 1992 and using the Kharin approach?\n",
    "Perhaps this will make the transition a little smoother, though fitting a trend over 20 years is questionable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279813ef-0a3e-4a03-b417-c4a9c8375f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_Kharin(hcst, obs):\n",
    "    def _linear_fit_in_time(da):\n",
    "        p = []\n",
    "        for l in da.lead:\n",
    "            ts = da.sel(lead=l).swap_dims({\"init\": \"time\"})\n",
    "            p.append(ts.polyfit(dim=\"time\", deg=1).expand_dims(lead=[l]))\n",
    "        return xr.concat(p, dim=\"lead\")\n",
    "\n",
    "    hcst_coeffs = _linear_fit_in_time(hcst)\n",
    "    hcst_coeffs = hcst_coeffs.rename(\n",
    "        {n: n.removesuffix(\"_polyfit_coefficients\") for n in hcst_coeffs.data_vars}\n",
    "    )\n",
    "    obs_coeffs = obs.polyfit(\"time\", deg=1)\n",
    "    obs_coeffs = obs_coeffs.rename(\n",
    "        {n: n.removesuffix(\"_polyfit_coefficients\") for n in obs_coeffs.data_vars}\n",
    "    )\n",
    "\n",
    "    slope_bias_coeffs = hcst_coeffs - obs_coeffs\n",
    "    slope_bias = xr.polyval(hcst[\"init\"], slope_bias_coeffs)\n",
    "    hcst_slope_corrected = hcst - slope_bias\n",
    "\n",
    "    bias = bias_mean(hcst_slope_corrected, obs)\n",
    "\n",
    "    return slope_bias + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d39808-b955-4f87-b16d-08abdd1c2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_year = 1992\n",
    "\n",
    "period_1 = [\n",
    "    cftime.DatetimeJulian(1973, 10, 1),\n",
    "    cftime.DatetimeJulian(1992, 10, 1),\n",
    "]  # 20 years, using initial dates < 1992\n",
    "period_2 = [\n",
    "    cftime.DatetimeJulian(2002, 10, 1),\n",
    "    cftime.DatetimeJulian(2021, 10, 1),\n",
    "]  # 20 years, using initial dates >= 1992\n",
    "\n",
    "bias_1 = bias_Kharin(\n",
    "    f5_hcst.where((f5_hcst.time >= period_1[0]) & (f5_hcst.time <= period_1[1])),\n",
    "    obs.where((obs.time >= period_1[0]) & (obs.time <= period_1[1])),\n",
    ")\n",
    "\n",
    "bias_2 = bias_Kharin(\n",
    "    f5_hcst.where((f5_hcst.time >= period_2[0]) & (f5_hcst.time <= period_2[1])),\n",
    "    obs.where((obs.time >= period_2[0]) & (obs.time <= period_2[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc1 = f6_hcst.sel(init=slice(None, str(transition_year - 1))) - bias_1\n",
    "f6_hcst_bc2 = f6_hcst.sel(init=slice(str(transition_year), None)) - bias_2\n",
    "f6_hcst_bc = xr.concat((f6_hcst_bc1, f6_hcst_bc2), dim=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7f90f-78ed-420c-9062-310e3bcc5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f1961-0b77-43ad-b4b0-72a0eec0d3d6",
   "metadata": {},
   "source": [
    "### This introduces a discontinuity. What about first removing the mean bias either side of 1992 first, then adjusting the slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255bf8c-8962-47dd-bf89-e1d431ed2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_year = 1992\n",
    "\n",
    "period_1 = [\n",
    "    cftime.DatetimeJulian(1973, 10, 1),\n",
    "    cftime.DatetimeJulian(1992, 10, 1),\n",
    "]  # 20 years, using initial dates < 1992\n",
    "period_2 = [\n",
    "    cftime.DatetimeJulian(2002, 10, 1),\n",
    "    cftime.DatetimeJulian(2021, 10, 1),\n",
    "]  # 20 years, using initial dates >= 1992\n",
    "\n",
    "bias_1 = bias_mean(\n",
    "    f5_hcst.where((f5_hcst.time >= period_1[0]) & (f5_hcst.time <= period_1[1])),\n",
    "    obs.where((obs.time >= period_1[0]) & (obs.time <= period_1[1])),\n",
    ")\n",
    "\n",
    "bias_2 = bias_mean(\n",
    "    f5_hcst.where((f5_hcst.time >= period_2[0]) & (f5_hcst.time <= period_2[1])),\n",
    "    obs.where((obs.time >= period_2[0]) & (obs.time <= period_2[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc1 = f6_hcst.sel(init=slice(None, str(transition_year - 1))) - bias_1\n",
    "f6_hcst_bc2 = f6_hcst.sel(init=slice(str(transition_year), None)) - bias_2\n",
    "f6_hcst_bc = xr.concat((f6_hcst_bc1, f6_hcst_bc2), dim=\"init\")\n",
    "\n",
    "\n",
    "# Adjust the slope\n",
    "period = [cftime.DatetimeJulian(1991, 10, 1), cftime.DatetimeJulian(2020, 10, 1)]\n",
    "\n",
    "bias = bias_Kharin(\n",
    "    f6_hcst_bc.where((f6_hcst.time >= period[0]) & (f6_hcst.time <= period[1])),\n",
    "    obs.where((obs.time >= period[0]) & (obs.time <= period[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc = f6_hcst_bc - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8792e0-c0d5-4db5-a123-b7f3326064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929f66b-d1d6-4fcf-8685-3a2e8cb5a2eb",
   "metadata": {},
   "source": [
    "### The inclusion of the slope adjustment does not obviously improve things. What about just using the Kharin approach outright. This feels a little \"off\" because it's using a feature of the approach for the wrong reason..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93853949-f7bb-4fac-a289-f6c2482272c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = [\n",
    "    cftime.DatetimeJulian(1971, 10, 1),\n",
    "    cftime.DatetimeJulian(2020, 10, 1),\n",
    "]\n",
    "\n",
    "bias = bias_Kharin(\n",
    "    f5_hcst.where((f5_hcst.time >= period[0]) & (f5_hcst.time <= period[1])),\n",
    "    obs.where((obs.time >= period[0]) & (obs.time <= period[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc = f6_hcst - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d718a9-742a-4c1c-8172-b6ea78207f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73cbd7-c1d1-4947-a38a-2467abb13803",
   "metadata": {},
   "source": [
    "### Last thing to try: remove an offset calculated from CAFE-60, prior to performing the bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbaeb7-4cac-4cd6-9508-3591a7d14c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the offset\n",
    "transition_year = 1992\n",
    "period_1 = slice(\"1964\", str(transition_year - 1))  # 28 years\n",
    "period_2 = slice(str(transition_year), \"2019\")  # 28 years\n",
    "\n",
    "bias_1 = cafe_60.sel(time=period_1).mean(\"time\") - obs.sel(time=period_1).mean(\"time\")\n",
    "bias_2 = cafe_60.sel(time=period_2).mean(\"time\") - obs.sel(time=period_2).mean(\"time\")\n",
    "\n",
    "f6_hcst_bc1 = f6_hcst.sel(init=slice(None, str(transition_year - 1))) - bias_1\n",
    "f6_hcst_bc2 = f6_hcst.sel(init=slice(str(transition_year), None)) - bias_2\n",
    "f6_hcst_bc = xr.concat((f6_hcst_bc1, f6_hcst_bc2), dim=\"init\")\n",
    "\n",
    "# Lead dependent bias correction\n",
    "period = [cftime.DatetimeJulian(1991, 10, 1), cftime.DatetimeJulian(2020, 10, 1)]\n",
    "\n",
    "bias = bias_mean(\n",
    "    f6_hcst_bc.where((f6_hcst_bc.time >= period[0]) & (f6_hcst_bc.time <= period[1])),\n",
    "    obs.where((obs.time >= period[0]) & (obs.time <= period[1])),\n",
    ")\n",
    "\n",
    "f6_hcst_bc = f6_hcst_bc - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9abd39-25a8-4ef9-b05b-bc8b54ad5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hindcasts(f6_hcst, f6_hcst_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7535f30-d9b5-458d-8c41-f6509c45a01d",
   "metadata": {},
   "source": [
    "### Could we just do all verification relative to CAFE60v1? How would we interpret this? Can we justify that this is a sensible thing to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf0318-2456-436a-af8c-9d04d309e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f425a32-24a8-4494-8097-0e79ef533845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cafe-f6 analysis)",
   "language": "python",
   "name": "cafe-f6_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
