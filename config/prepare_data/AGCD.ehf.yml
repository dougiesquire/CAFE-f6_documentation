# Config file for specifying processing using src.prepare_data()
# ==================================================================================

# name: required
#    The name of the dataset. Must match a method in src.prepare_data._open
#
# prepare: required
#    List of unique identifiers for output variables to prepare and save. This will 
#    be used to save the prepared output variable(s) as {name}.{identifier}.zarr. 
#    Each identifier can include the following:
#
#    uses: required
#        List of input variables required to compute the output variable(s). For 
#        some datasets, this should be further broken into subkeys indicating the 
#        realm for each list of variables (e.g. ocean_month). Alternatively, users 
#        can provide the identifier of a previously prepared dataset by entering
#        `prepared: <identifier>`.
#    preprocess: optional
#        Functions and kwargs from src.utils to be applied sequentially prior to 
#        concatenation (for datasets comprised of multiple concatenated files) 
#        and/or prior to merging input variables from multiple realms where more 
#        than one are specified.
#    apply: optional
#        Functions and kwargs from src.utils to be applied sequentially to opened 
#        (and concatenated/merge, where appropriate) dataset.

name: "AGCD"

prepare:

  # Prepare Excess Heat Factor over Australia
  # ================================================
  
  # Daily t_ref

  daily.full.t_ref_Aus:
    uses:
      - "tmin"
      - "tmax"
    preprocess:
      rechunk:
        time: 50
        lat: -1
        lon: -1
    apply:
      calculate_tmean_from_tmin_tmax:
        tmean_name: "t_ref"
      convert_calendar:
        calendar: "noleap"
      round_to_start_of_day:
        dim: "time"
      interpolate_to_grid_from_file:
        file: "data/raw/gridinfo/CAFE_atmos_grid.nc"
      extract_lon_lat_box:
        box: [110, 155, -45, -9]
        weighted_average: False
      rechunk:
        time: -1
        
  # 95th percentile of daily t_ref
        
  daily.p95_1971-2000.t_ref_Aus:
    uses:
      prepared:
        - "daily.full.t_ref_Aus"
    apply:
      calculate_percentile_thresholds:
        percentile: 0.95
        percentile_period: ["1971-01-01", "2000-12-31"]

  # Daily EHF
  
  daily.full.ehf_Aus:
    uses:
      prepared:
        - "daily.full.t_ref_Aus"
    apply:
      calculate_EHF:
        T_p95_file: "data/processed/AGCD.daily.p95_1971-2000.t_ref_Aus.zarr"
      rechunk:
        time: -1
        
  # 85th percentile of daily EHF
  
  daily.p85_1958-2011.ehf_Aus:
    uses:
      prepared:
        - "daily.full.ehf_Aus"
    apply:
      where_greater_than:
        value: 0
      calculate_percentile_thresholds:
        percentile: 0.85
        percentile_period: ["1958-01-01", "2011-12-31"]
        
  # Daily EHF severity
  
  daily.full.ehf_severity_Aus:
    uses:
      prepared:
        - "daily.full.t_ref_Aus"
    apply:
      calculate_EHF_severity:
        T_p95_file: "data/processed/AGCD.daily.p95_1971-2000.t_ref_Aus.zarr"
        EHF_p85_file: "data/processed/AGCD.daily.p85_1958-2011.ehf_Aus.zarr"
      rechunk:
        time: -1
        
  # Annual days over 0
  
  annual.days_over_0.ehf_severity_Aus:
    uses:
      prepared:
        - "daily.full.ehf_severity_Aus"
    apply:
      greater_than:
        value: 0
      coarsen:
        window_size: 365
        start_points: ["1960-11-01"]
        dim: "time"
      round_to_start_of_month:
        dim: "time"
      rechunk:
        time: -1
        
  # 4-year days over 0
  
  4-year.days_over_0.ehf_severity_Aus:
    uses:
      prepared:
        - "annual.days_over_0.ehf_severity_Aus"
    apply:
      rolling_mean:
        window_size: 4
      rechunk:
        time: -1